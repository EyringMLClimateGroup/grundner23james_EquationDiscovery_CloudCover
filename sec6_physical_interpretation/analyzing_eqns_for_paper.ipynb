{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physical Interpretation of Best Analytic Models\n",
    "\n",
    "Taking only the PySR schemes from the Pareto frontier and their modified version that *always* satisfies the RH-constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ran with Python 3 environment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "import sys\n",
    "import sympy as sp\n",
    "\n",
    "sys.path.insert(0, '~/workspace_icon-ml/cloud_cover_parameterization')\n",
    "\n",
    "import tensorflow as tf\n",
    "import my_classes\n",
    "import time\n",
    "import json\n",
    "\n",
    "from my_classes import read_mean_and_std\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow import nn\n",
    "\n",
    "abspath = '~/workspace_icon-ml/symbolic_regression/evaluate_schemes/analyzing_eqns/v1/'\n",
    "\n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "matplotlib.use('PDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "base_path = '/home/b/b309170'\n",
    "output_path = base_path + '/my_work/icon-ml_data/cloud_cover_parameterization/neighborhood_based_SR_DYAMOND'\n",
    "\n",
    "input_data = np.load(output_path + '/cloud_cover_input_dyamond.npy')\n",
    "output_data = np.load(output_path + '/cloud_area_output_dyamond.npy')\n",
    "\n",
    "# To locate variables\n",
    "features = ['hus', 'clw', 'cli', 'ta', 'pa', 'zg', 'fr_land', 'U', 'rh', 'ps', 'hus_z', 'hus_zz', 'clw_z', 'clw_zz', 'cli_z',\\\n",
    "                  'cli_zz', 'ta_z', 'ta_zz', 'pa_z', 'pa_zz', 'U_z', 'U_zz', 'rh_z', 'rh_zz']\n",
    "len(features)\n",
    "\n",
    "loc = {}\n",
    "for i in range(len(features)):\n",
    "    loc[features[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with random subset (the entire dataset takes too much memory)\n",
    "np.random.seed(10)\n",
    "rand_int = np.random.randint(0, input_data.shape[0], 10**8)\n",
    "\n",
    "input_data = input_data[rand_int]\n",
    "output_data = output_data[rand_int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "mean,std = read_mean_and_std('~/workspace_icon-ml/cloud_cover_parameterization/neighborhood_based_SR_DYAMOND/saved_models/cross_validation_neighborhood_based_sr_cl_area_fold_2.txt')\n",
    "\n",
    "input_data_scaled = (input_data - mean)/std\n",
    "\n",
    "all_features = ['hus', 'clw', 'cli', 'ta', 'pa', 'zg', 'fr_land', 'U', 'rh', 'ps', 'hus_z', 'hus_zz', 'clw_z', 'clw_zz', 'cli_z', 'cli_zz', 'ta_z', 'ta_zz', 'pa_z', 'pa_zz', 'U_z', 'U_zz', 'rh_z', 'rh_zz']\n",
    "\n",
    "loc_all = {}\n",
    "for i in range(len(all_features)):\n",
    "    loc_all[all_features[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best PySR equations\n",
    "with open('~/workspace_icon-ml/symbolic_regression/finding_symmetries/pysr_results_dyamond_on_regimes/no_of_regimes_2/optimized_eqns.json', 'r') as file:\n",
    "    pysr_eqns = json.load(file)\n",
    "    \n",
    "rh, ta, rh_z, cli, clw = sp.symbols('rh ta rh_z cli clw')\n",
    "x0, x1, x2, x3, x4 = sp.symbols('x0 x1 x2 x3 x4')\n",
    "    \n",
    "pysr_EQ1 = sp.lambdify((rh, ta, rh_z, cli, clw), pysr_eqns['EQ1']['Equation w.r.t. physical vars'])\n",
    "pysr_EQ4 = sp.lambdify((rh, ta, rh_z, cli, clw), pysr_eqns['EQ4']['Equation w.r.t. physical vars'])\n",
    "\n",
    "def pysr_EQ1_mod(rh, ta, rh_z, cli, clw):\n",
    "    # Artificially increase RH to ensure RH-constraint\n",
    "    (a,b,c,d) = (38.85954116, 42.70818472, 19.34746465, 1.11321032)\n",
    "    \n",
    "    x0 = (rh - mean[loc_all['rh']])/std[loc_all['rh']]\n",
    "    x1 = (ta - mean[loc_all['ta']])/std[loc_all['ta']]\n",
    "    \n",
    "    x0 = np.maximum(x0, 1/(2*c*d)*(-c*x1**2-a))\n",
    "    \n",
    "    rh = x0*std[loc_all['rh']] + mean[loc_all['rh']]\n",
    "    \n",
    "    return pysr_EQ1(rh, ta, rh_z, cli, clw)    \n",
    "    \n",
    "def pysr_EQ4_mod(rh, ta, rh_z, cli, clw):\n",
    "    # Artificially increase RH to ensure RH-constraint\n",
    "    (a,b,c,d) = (38.6562122, 43.53500518, 19.78403208, 1.13637902)\n",
    "    \n",
    "    x0 = (rh - mean[loc_all['rh']])/std[loc_all['rh']]\n",
    "    x1 = (ta - mean[loc_all['ta']])/std[loc_all['ta']]\n",
    "    \n",
    "    x0 = np.maximum(x0, 1/(2*c*d)*(-c*x1**2-a))\n",
    "    \n",
    "    rh = x0*std[loc_all['rh']] + mean[loc_all['rh']]\n",
    "    \n",
    "    return pysr_EQ4(rh, ta, rh_z, cli, clw)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 14:38:55.916245: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-13 14:38:55.917797: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-13 14:38:55.918401: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (l40054.lvt.dkrz.de): /proc/driver/nvidia/version does not exist\n",
      "2023-03-13 14:38:55.928255: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Load NN\n",
    "custom_objects = {}\n",
    "custom_objects['leaky_relu'] = nn.leaky_relu\n",
    "\n",
    "# SFS 24 (from workspace/cloud_cover_parameterization/neighborhood_based_SR_DYAMOND/saved_models/cross_validation_neighborhood_based_sr_cl_area_fold_2.h5)\n",
    "sfs_24_nn = load_model('~/workspace_icon-ml/cloud_cover_parameterization/neighborhood_based_SR_DYAMOND/saved_models/cross_validation_neighborhood_based_sr_cl_area_fold_2.h5', custom_objects)\n",
    "\n",
    "def b(x):\n",
    "    return np.minimum(np.maximum(x, 0), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add data PDPs to the plots!\n",
    "# Runs for 70s*len(X_vals)\n",
    "def find_closest_samples(X, X_vals, N):\n",
    "    '''\n",
    "        X [str]: The feature, for which we should not use the mean\n",
    "        X_vals [list(float)]: The values for the scaled! features (instead of the mean)\n",
    "        N [int]: The number of closest samples, that shall be in the output\n",
    "        returns: The indices of the N closest samples\n",
    "    '''\n",
    "    indices = np.zeros((input_data_scaled.shape[0], len(X_vals)))\n",
    "    \n",
    "    feats = ['rh', 'ta', 'rh_z', 'cli', 'clw']\n",
    "    feats.remove(X)\n",
    "    feat_inds = [loc[feat] for feat in feats]\n",
    "    s = np.sum(np.abs(input_data_scaled[:, feat_inds]), axis=1)\n",
    "    \n",
    "    for k in range(len(X_vals)):\n",
    "        indices[:, k] = s + np.abs(input_data_scaled[:, loc[X]] - X_vals[k])\n",
    "        \n",
    "    sorted_inds = np.argsort(indices, axis=0) # Takes most of the time\n",
    "    return sorted_inds[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_mean = np.mean(input_data[:, loc['ta']])\n",
    "rh_z_mean = np.mean(input_data[:, loc['rh_z']])\n",
    "cli_mean = np.mean(input_data[:, loc['cli']])\n",
    "clw_mean = np.mean(input_data[:, loc['clw']])\n",
    "rh_mean = np.mean(input_data[:, loc['rh']])\n",
    "\n",
    "ta_std = np.mean(input_data[:, loc['ta']])\n",
    "rh_z_std = np.mean(input_data[:, loc['rh_z']])\n",
    "cli_std = np.mean(input_data[:, loc['cli']])\n",
    "clw_std = np.mean(input_data[:, loc['clw']])\n",
    "rh_std = np.mean(input_data[:, loc['rh']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Relative Humidity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.66198778152466"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Runs for 80 mins, with all data! For 17 minutes with 10**8 samples.\n",
    "rh_vals = np.linspace(np.min(input_data[:, loc['rh']]), 1.1, 40)\n",
    "\n",
    "# sample_indices = find_closest_samples('rh', (rh_vals - rh_mean)/rh_std, 100) # The Bottleneck! Scales with O(len(rh_vals)).\n",
    "# output_mean_data = [np.mean(output_data[sample_indices[:, k]]) for k in range(len(rh_vals))]\n",
    "\n",
    "output_sfs_nn_24 = []\n",
    "for rh in rh_vals:\n",
    "    input_arr = np.expand_dims((np.mean(input_data, axis=0) - mean)/std, 0)\n",
    "    input_arr[0, loc['rh']] = (rh - mean[loc['rh']])/std[loc['rh']]\n",
    "    pred = b(sfs_24_nn.predict(input_arr))\n",
    "    output_sfs_nn_24.append(pred)\n",
    "\n",
    "# To be able to save the numbers\n",
    "plot_values = {}\n",
    "plot_values['RH values'] = list(rh_vals)\n",
    "for eq_num in ['1', '1_mod', '4', '4_mod']:\n",
    "    plot_values['pysr_EQ%s'%eq_num] = list(b(locals()['pysr_EQ%s'%eq_num](rh_vals, ta_mean, rh_z_mean, cli_mean, clw_mean)))\n",
    "plot_values['sfs_nn_24'] = list(np.float64(np.array(output_sfs_nn_24)[:,0,0]))\n",
    "# plot_values['data_mean'] = list(np.float64(output_mean_data))\n",
    "    \n",
    "# plt.plot(rh_vals, plot_values['pysr_EQ1'], color=CB_color_cycle[0])\n",
    "# plt.plot(rh_vals, plot_values['pysr_EQ1_mod'], color=CB_color_cycle[1])\n",
    "plt.plot(rh_vals, plot_values['pysr_EQ4'], color=CB_color_cycle[0])\n",
    "plt.plot(rh_vals, plot_values['pysr_EQ4_mod'], color=CB_color_cycle[1])\n",
    "plt.plot(rh_vals, plot_values['sfs_nn_24'], color=CB_color_cycle[2])\n",
    "# plt.plot(rh_vals, plot_values['data_mean'], color='black')\n",
    "plt.title('b) $f_{mean}$(RH)')\n",
    "# plt.legend(['PySR equation', 'PySR eq., PC$_3$ enforced', 'SFS NN 24', 'DYAMOND cl_area'])\n",
    "plt.legend(['PySR equation', 'PySR eq., PC$_3$ enforced', 'SFS24 NN'])\n",
    "plt.xlabel('Relative Humidity')\n",
    "plt.ylabel('Cloud Cover [%]')\n",
    "plt.savefig('~/workspace_icon-ml/symbolic_regression/evaluate_schemes/analyzing_eqns/v1/RH_vs_cl_area_mod.pdf')\n",
    "\n",
    "# Restore default figsize\n",
    "plt.close()\n",
    "plt.clf()\n",
    "plt.figure()\n",
    "\n",
    "time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(abspath, 'RH_plot_values_mod.json'), 'w') as file:\n",
    "    json.dump(plot_values, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Temperature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ta_vals = np.linspace(np.min(input_data[:, loc['ta']]), np.max(input_data[:, loc['ta']]), 40)\n",
    "\n",
    "sample_indices = find_closest_samples('ta', (ta_vals - ta_mean)/ta_std, 100)\n",
    "output_mean_data = [np.mean(output_data[sample_indices[:, k]]) for k in range(len(ta_vals))]\n",
    "\n",
    "output_sfs_nn_24 = []\n",
    "for ta in ta_vals:\n",
    "    input_arr = np.expand_dims((np.mean(input_data, axis=0) - mean)/std, 0)\n",
    "    input_arr[0, loc['ta']] = (ta - mean[loc['ta']])/std[loc['ta']]\n",
    "    pred = b(sfs_24_nn.predict(input_arr))\n",
    "    output_sfs_nn_24.append(pred)\n",
    "    \n",
    "# To be able to save the numbers\n",
    "plot_values = {}\n",
    "plot_values['T values'] = list(ta_vals)\n",
    "for eq_num in ['1', '1_mod', '4', '4_mod']:\n",
    "    plot_values['pysr_EQ%s'%eq_num] = list(b(locals()['pysr_EQ%s'%eq_num](rh_mean, ta_vals, rh_z_mean, cli_mean, clw_mean)))\n",
    "plot_values['sfs_nn_24'] = list(np.float64(np.array(output_sfs_nn_24)[:,0,0]))\n",
    "plot_values['data_mean'] = list(np.float64(output_mean_data))\n",
    "    \n",
    "# plt.plot(ta_vals, plot_values['pysr_EQ1'], color=CB_color_cycle[0])\n",
    "# plt.plot(ta_vals, plot_values['pysr_EQ1_mod'], color=CB_color_cycle[1])\n",
    "# plt.plot(ta_vals, plot_values['pysr_EQ4'], color=CB_color_cycle[2])\n",
    "plt.plot(ta_vals, plot_values['pysr_EQ4_mod'], color=CB_color_cycle[0])\n",
    "plt.plot(ta_vals, plot_values['sfs_nn_24'], color=CB_color_cycle[1])\n",
    "plt.plot(ta_vals, plot_values['data_mean'], color='black')\n",
    "# plt.title('Based on means')\n",
    "plt.legend(['PySR eq. (PC$_3$ enforced)', 'SFS NN 24', 'DYAMOND cl_area'])\n",
    "plt.xlabel('Temperature [K]')\n",
    "plt.ylabel('Cloud Cover')\n",
    "plt.savefig('~/workspace_icon-ml/symbolic_regression/evaluate_schemes/analyzing_eqns/T_vs_cl_area_mod.pdf')\n",
    "\n",
    "# Restore default figsize\n",
    "plt.close()\n",
    "plt.clf()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(abspath, 'T_plot_values_mod.json'), 'w') as file:\n",
    "    json.dump(plot_values, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Relative Humidity and Temperature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the general font size\n",
    "matplotlib.rcParams['legend.fontsize'] = 'x-large'\n",
    "matplotlib.rcParams['axes.labelsize'] = 'x-large' # For an axes xlabel and ylabel\n",
    "matplotlib.rcParams['axes.titlesize'] = 'x-large'\n",
    "matplotlib.rcParams['xtick.labelsize'] = 'xx-large'\n",
    "matplotlib.rcParams['ytick.labelsize'] = 'xx-large'\n",
    "ax.set_title('title', fontsize=1)\n",
    "\n",
    "from pylab import meshgrid,cm,imshow,contour,clabel,colorbar,axis,title,show\n",
    "\n",
    "# Define the bounds\n",
    "rh_min = np.min(input_data[:, loc['rh']])\n",
    "rh_max = np.max(input_data[:, loc['rh']])\n",
    "ta_min = np.min(input_data[:, loc['ta']])\n",
    "ta_max = np.max(input_data[:, loc['ta']])\n",
    "\n",
    "# Number of pixels in x- and y-direction\n",
    "N_x = 30\n",
    "N_y = 30\n",
    " \n",
    "x = np.linspace(rh_min, rh_max, N_x)\n",
    "y = np.linspace(ta_min, ta_max, N_y)\n",
    "X,Y = meshgrid(x, y)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.01)\n",
    "\n",
    "axes = (0,1,2,3)\n",
    "for i, title_name in enumerate(['PySR equation', 'PySR equation, PC$_3$ enforced', 'SFS NN 24', 'DYAMOND cloud area fraction']):\n",
    "    # Add new subplot iteratively\n",
    "    ax = plt.subplot(2, 2, i + 1)\n",
    "    axis = axes[:i] + axes[(i+1):]\n",
    "    \n",
    "    ## Evaluation of the function on the grid\n",
    "    # if i == 0:\n",
    "    #     Z = b(locals()['pysr_EQ1'](X, Y, rh_z_mean, cli_mean, clw_mean))\n",
    "    # elif i == 1:\n",
    "    #     Z = b(locals()['pysr_EQ1_mod'](X, Y, rh_z_mean, cli_mean, clw_mean))\n",
    "    if i == 0:\n",
    "        Z = b(locals()['pysr_EQ4'](X, Y, rh_z_mean, cli_mean, clw_mean))\n",
    "    elif i == 1:\n",
    "        Z = b(locals()['pysr_EQ4_mod'](X, Y, rh_z_mean, cli_mean, clw_mean))\n",
    "    elif i == 2:\n",
    "        # Take data-means and scale by mean/std of the NN\n",
    "        input_arr = (np.mean(input_data, axis=0) - mean)/std\n",
    "        # Initialize mesh for every feature with its scaled mean\n",
    "        input_mesh = np.ones((len(mean), N_x, N_y))\n",
    "        for k in range(len(input_arr)):\n",
    "            input_mesh[k] = input_arr[k]*np.ones((N_x, N_y))\n",
    "        # Substitute average RH and temperature by scaled X,Y - values\n",
    "        input_mesh[loc['rh']] = (X - mean[loc['rh']])/std[loc['rh']]\n",
    "        input_mesh[loc['ta']] = (Y - mean[loc['ta']])/std[loc['ta']]\n",
    "        # Reshape to predict\n",
    "        input_mesh_rs = input_mesh.reshape(24, -1).T\n",
    "        Z = b(sfs_24_nn.predict(input_mesh_rs))\n",
    "        # Reshape back to plot\n",
    "        Z = Z.T.reshape(N_x, N_y)\n",
    "    elif i == 3:     \n",
    "        step_rh = x[1] - x[0]\n",
    "        inds_rh = np.round((input_data[:, loc['rh']] - rh_min)/step_rh)\n",
    "\n",
    "        step_ta = y[1] - y[0]\n",
    "        inds_ta = np.round((input_data[:, loc['ta']] - ta_min)/step_ta)\n",
    "        \n",
    "        Z = np.zeros((N_x, N_y))\n",
    "        for M in range(N_x):\n",
    "            for N in range(N_y):\n",
    "                data_in_box = output_data[np.intersect1d(np.where(inds_rh == M)[0], np.where(inds_ta == N)[0])]\n",
    "                if len(data_in_box) > 1000:\n",
    "                    Z[M, N] = np.mean(data_in_box)\n",
    "                else:\n",
    "                    Z[M,N] = None\n",
    "        # It looks like we have to transpose the output here\n",
    "        Z = Z.T\n",
    "                \n",
    "    title(title_name)\n",
    "    im = ax.imshow(Z, vmin=0, vmax=100, cmap='Blues_r') \n",
    "\n",
    "    ## Replace tick labels by proper tick labels. It's a bit cumbersome with imshow.\n",
    "    # f_x = max(np.arange(0, N_x, N_x/5))/100 # The last tick is not necessarily at the end of the axis\n",
    "    # f_y = max(np.arange(0, N_y, N_y/5))/100 # The last tick is not necessarily at the end of the axis\n",
    "    plt.xticks(np.arange(0, N_x, N_x/5), ['%.1f'%val for val in np.linspace(min(x), max(x), 5)])\n",
    "    plt.yticks(np.arange(0, N_y, N_y/5), ['%d'%val for val in np.linspace(min(y), max(y), 5)])\n",
    "\n",
    "    # Adding the Contour lines with labels\n",
    "    cset = ax.contour(Z, np.arange(10,100,40),linewidths=3,cmap=cm.Set2)\n",
    "    ax.clabel(cset,inline=True,fmt='%1.1f',fontsize=10)\n",
    "    colorbar(im) # adding the colobar on the right\n",
    "    # # latex fashion title\n",
    "    if i in [2,3]:\n",
    "        plt.xlabel('Relative Humidity')\n",
    "    if i in [0,2]:\n",
    "        plt.ylabel('Temperature [K]')\n",
    "    # show()\n",
    "    \n",
    "plt.savefig('~/workspace_icon-ml/symbolic_regression/evaluate_schemes/analyzing_eqns/rh_and_T_vs_cl_area_mod.pdf')\n",
    "\n",
    "# Restore default figsize\n",
    "plt.close()\n",
    "plt.clf()\n",
    "plt.figure()\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cloud Ice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cli_vals = np.linspace(np.min(input_data[:, loc['cli']]), np.max(input_data[:, loc['cli']]), 40)\n",
    "\n",
    "sample_indices = find_closest_samples('cli', (cli_vals - cli_mean)/cli_std, 100)\n",
    "output_mean_data = [np.mean(output_data[sample_indices[:, k]]) for k in range(len(cli_vals))]\n",
    "\n",
    "output_sfs_nn_24 = []\n",
    "for cli in cli_vals:\n",
    "    input_arr = np.expand_dims((np.mean(input_data, axis=0) - mean)/std, 0)\n",
    "    input_arr[0, loc['cli']] = (cli - mean[loc['cli']])/std[loc['cli']]\n",
    "    pred = b(sfs_24_nn.predict(input_arr))\n",
    "    output_sfs_nn_24.append(pred)\n",
    "    \n",
    "# To be able to save the numbers\n",
    "plot_values = {}\n",
    "plot_values['cli values'] = list(cli_vals)\n",
    "for eq_num in ['1', '1_mod', '4', '4_mod']:\n",
    "    plot_values['pysr_EQ%s'%eq_num] = list(b(locals()['pysr_EQ%s'%eq_num](rh_mean, ta_mean, rh_z_mean, cli_vals, clw_mean)))\n",
    "plot_values['sfs_nn_24'] = list(np.float64(np.array(output_sfs_nn_24)[:,0,0]))\n",
    "plot_values['data_mean'] = list(np.float64(output_mean_data))\n",
    "    \n",
    "# plt.plot(cli_vals, plot_values['pysr_EQ1'], color=CB_color_cycle[0])\n",
    "# plt.plot(cli_vals, plot_values['pysr_EQ1_mod'], color=CB_color_cycle[1])\n",
    "# plt.plot(cli_vals, plot_values['pysr_EQ4'], color=CB_color_cycle[2])\n",
    "plt.plot(cli_vals, plot_values['pysr_EQ4_mod'], color=CB_color_cycle[0])\n",
    "plt.plot(cli_vals, plot_values['sfs_nn_24'], color=CB_color_cycle[1])\n",
    "plt.plot(cli_vals, plot_values['data_mean'], color='black')\n",
    "# plt.title('Based on means')\n",
    "plt.legend(['PySR eq. (PC$_3$ enforced)', 'SFS NN 24', 'DYAMOND cl_area'])\n",
    "plt.xlabel('Cloud Ice [kg/kg]')\n",
    "plt.ylabel('Cloud Cover')\n",
    "plt.savefig('~/workspace_icon-ml/symbolic_regression/evaluate_schemes/analyzing_eqns/qi_vs_cl_area_mod.pdf')\n",
    "\n",
    "# Restore default figsize\n",
    "plt.close()\n",
    "plt.clf()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(abspath, 'qi_plot_values_mod.json'), 'w') as file:\n",
    "    json.dump(plot_values, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cloud Water**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clw_vals = np.linspace(np.min(input_data[:, loc['clw']]), np.max(input_data[:, loc['clw']]), 40)\n",
    "\n",
    "sample_indices = find_closest_samples('clw', (clw_vals - clw_mean)/clw_std, 100)\n",
    "output_mean_data = [np.mean(output_data[sample_indices[:, k]]) for k in range(len(clw_vals))]\n",
    "\n",
    "output_sfs_nn_24 = []\n",
    "for clw in clw_vals:\n",
    "    input_arr = np.expand_dims((np.mean(input_data, axis=0) - mean)/std, 0)\n",
    "    input_arr[0, loc['clw']] = (clw - mean[loc['clw']])/std[loc['clw']]\n",
    "    pred = b(sfs_24_nn.predict(input_arr))\n",
    "    output_sfs_nn_24.append(pred)\n",
    "    \n",
    "# To be able to save the numbers\n",
    "plot_values = {}\n",
    "plot_values['qc values'] = list(clw_vals)\n",
    "for eq_num in ['1', '1_mod', '4', '4_mod']:\n",
    "    plot_values['pysr_EQ%s'%eq_num] = list(b(locals()['pysr_EQ%s'%eq_num](rh_mean, ta_mean, rh_z_mean, cli_mean, clw_vals)))\n",
    "plot_values['sfs_nn_24'] = list(np.float64(np.array(output_sfs_nn_24)[:,0,0]))\n",
    "plot_values['data_mean'] = list(np.float64(output_mean_data))\n",
    "    \n",
    "# plt.plot(clw_vals, plot_values['pysr_EQ1'], color=CB_color_cycle[0])\n",
    "# plt.plot(clw_vals, plot_values['pysr_EQ1_mod'], color=CB_color_cycle[1])\n",
    "# plt.plot(clw_vals, plot_values['pysr_EQ4'], color=CB_color_cycle[2])\n",
    "plt.plot(clw_vals, plot_values['pysr_EQ4_mod'], color=CB_color_cycle[0])\n",
    "plt.plot(clw_vals, plot_values['sfs_nn_24'], color=CB_color_cycle[1])\n",
    "plt.plot(clw_vals, plot_values['data_mean'], color='black')\n",
    "# plt.title('Based on means')\n",
    "plt.legend(['PySR eq. (PC$_3$ enforced)', 'SFS NN 24', 'DYAMOND cl_area'])\n",
    "plt.xlabel('Cloud Water [kg/kg]')\n",
    "plt.ylabel('Cloud Cover')\n",
    "plt.savefig('~/workspace_icon-ml/symbolic_regression/evaluate_schemes/analyzing_eqns/qc_vs_cl_area_mod.pdf')\n",
    "\n",
    "# Restore default figsize\n",
    "plt.close()\n",
    "plt.clf()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(abspath, 'qc_plot_values_mod.json'), 'w') as file:\n",
    "    json.dump(plot_values, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cloud Water and Ice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Increase the general font size\n",
    "matplotlib.rcParams['legend.fontsize'] = 'x-large'\n",
    "matplotlib.rcParams['axes.labelsize'] = 'x-large' # For an axes xlabel and ylabel\n",
    "matplotlib.rcParams['axes.titlesize'] = 'x-large'\n",
    "matplotlib.rcParams['xtick.labelsize'] = 'xx-large'\n",
    "matplotlib.rcParams['ytick.labelsize'] = 'xx-large'\n",
    "ax.set_title('title', fontsize=1)\n",
    "\n",
    "from pylab import meshgrid,cm,imshow,contour,clabel,colorbar,axis,title,show\n",
    "\n",
    "# Define the bounds\n",
    "clw_min = np.min(input_data[:, loc['clw']])\n",
    "clw_max = np.max(input_data[:, loc['clw']])\n",
    "cli_min = np.min(input_data[:, loc['cli']])\n",
    "cli_max = np.max(input_data[:, loc['cli']])\n",
    "\n",
    "# Number of pixels in x- and y-direction\n",
    "N_x = 30\n",
    "N_y = 30\n",
    " \n",
    "# MAX DIVIDED BY 3\n",
    "x = np.linspace(clw_min, clw_max/3, N_x)\n",
    "y = np.linspace(cli_min, cli_max/3, N_y)\n",
    "X,Y = meshgrid(x, y)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.01)\n",
    "\n",
    "axes = (0,1,2,3)\n",
    "for i, title_name in enumerate(['PySR equation', 'PySR equation, PC$_3$ enforced', 'SFS NN 24', 'DYAMOND cloud area fraction']):\n",
    "    # Add new subplot iteratively\n",
    "    ax = plt.subplot(2, 2, i + 1)\n",
    "    axis = axes[:i] + axes[(i+1):]\n",
    "    \n",
    "    ## Evaluation of the function on the grid\n",
    "    # if i == 0:\n",
    "    #     Z = b(locals()['pysr_EQ1'](X, Y, rh_z_mean, cli_mean, clw_mean))\n",
    "    # elif i == 1:\n",
    "    #     Z = b(locals()['pysr_EQ1_mod'](X, Y, rh_z_mean, cli_mean, clw_mean))\n",
    "    if i == 0:\n",
    "        Z = b(locals()['pysr_EQ4'](rh_mean, ta_mean, rh_z_mean, Y, X))\n",
    "    elif i == 1:\n",
    "        Z = b(locals()['pysr_EQ4_mod'](rh_mean, ta_mean, rh_z_mean, Y, X))\n",
    "    elif i == 2:\n",
    "        # Take data-means and scale by mean/std of the NN\n",
    "        input_arr = (np.mean(input_data, axis=0) - mean)/std\n",
    "        # Initialize mesh for every feature with its scaled mean\n",
    "        input_mesh = np.ones((len(mean), N_x, N_y))\n",
    "        for k in range(len(input_arr)):\n",
    "            input_mesh[k] = input_arr[k]*np.ones((N_x, N_y))\n",
    "        # Substitute average RH and temperature by scaled X,Y - values\n",
    "        input_mesh[loc['clw']] = (X - mean[loc['clw']])/std[loc['clw']]\n",
    "        input_mesh[loc['cli']] = (Y - mean[loc['cli']])/std[loc['cli']]\n",
    "        # Reshape to predict\n",
    "        input_mesh_rs = input_mesh.reshape(24, -1).T\n",
    "        Z = b(sfs_24_nn.predict(input_mesh_rs))\n",
    "        # Reshape back to plot\n",
    "        Z = Z.T.reshape(N_x, N_y)\n",
    "    elif i == 3:     \n",
    "        step_clw = x[1] - x[0]\n",
    "        inds_clw = np.round((input_data[:, loc['clw']] - clw_min)/step_clw)\n",
    "\n",
    "        step_cli = y[1] - y[0]\n",
    "        inds_cli = np.round((input_data[:, loc['cli']] - cli_min)/step_cli)\n",
    "        \n",
    "        Z = np.zeros((N_x, N_y))\n",
    "        for M in range(N_x):\n",
    "            for N in range(N_y):\n",
    "                data_in_box = output_data[np.intersect1d(np.where(inds_clw == M)[0], np.where(inds_cli == N)[0])]\n",
    "                if len(data_in_box) > 1000:\n",
    "                    Z[M, N] = np.mean(data_in_box)\n",
    "                else:\n",
    "                    Z[M,N] = None\n",
    "        # It looks like we have to transpose the output here\n",
    "        Z = Z.T\n",
    "                \n",
    "    title(title_name)\n",
    "    im = ax.imshow(Z, vmin=0, vmax=100, cmap='Blues_r') \n",
    "\n",
    "    ## Replace tick labels by proper tick labels. It's a bit cumbersome with imshow.\n",
    "    # f_x = max(np.arange(0, N_x, N_x/5))/100 # The last tick is not necessarily at the end of the axis\n",
    "    # f_y = max(np.arange(0, N_y, N_y/5))/100 # The last tick is not necessarily at the end of the axis\n",
    "    plt.xticks(np.arange(0, N_x, N_x/5), ['%.1g'%val for val in np.linspace(min(x), max(x), 5)])\n",
    "    plt.yticks(np.arange(0, N_y, N_y/5), ['%.1g'%val for val in np.linspace(min(y), max(y), 5)])\n",
    "\n",
    "    # Adding the Contour lines with labels\n",
    "    cset = ax.contour(Z, np.arange(10,100,40),linewidths=3,cmap=cm.Set2)\n",
    "    ax.clabel(cset,inline=True,fmt='%1.1f',fontsize=10)\n",
    "    colorbar(im) # adding the colobar on the right\n",
    "    # # latex fashion title\n",
    "    if i in [2,3]:\n",
    "        plt.xlabel('Cloud Water [kg/kg]')\n",
    "    if i in [0,2]:\n",
    "        plt.ylabel('Cloud Ice [kg/kg]')\n",
    "    # show()\n",
    "    \n",
    "plt.savefig('~/workspace_icon-ml/symbolic_regression/evaluate_schemes/analyzing_eqns/clw_and_cli_vs_cl_area_mod.pdf')\n",
    "\n",
    "# Restore default figsize\n",
    "plt.close()\n",
    "plt.clf()\n",
    "plt.figure()\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (based on the module python3/2022.01)",
   "language": "python",
   "name": "python3_2022_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

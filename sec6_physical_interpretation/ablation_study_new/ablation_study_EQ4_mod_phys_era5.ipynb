{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e1eb9b8-ef59-40d3-854d-91ee4f68fa7a",
   "metadata": {},
   "source": [
    "**tmpw0h7p9s5, equation 22**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a758a875-1c32-45f6-b133-702feb45b76f",
   "metadata": {},
   "source": [
    "Ablation study on the DYAMOND data -- setting parameters to 0 and re-tuning\n",
    "\n",
    "--> Here in the physical form of the equation (I hope Nelder-Mead and BFGS won't fail because of that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127d6780-72b3-4441-8f55-1ef5eb3296f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 3 module\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import sympy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, os.environ['HOME'] + '/my_work/published_code/grundner23james_EquationDiscovery_CloudCover_addressing_reviews/sec2_data/')\n",
    "from functions import append_dict_to_json\n",
    "from sklearn import tree\n",
    "import my_classes\n",
    "from my_classes import load_data\n",
    "\n",
    "# sys.argv[1] = 10\n",
    "SEED = int(sys.argv[1])\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06ad58d-d470-4f09-bfcf-0b59efc5251c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3b78d22-4b0d-42eb-8d05-931b6085d955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q\n",
      "clwc\n",
      "ciwc\n",
      "t\n",
      "pa\n",
      "cc\n",
      "all\n",
      "Assertion warning. Max cc not 100. Instead:\n",
      "100.000015\n",
      "(1368, 27, 66655)\n",
      "(1368, 27, 66655)\n",
      "(1368, 27, 66655)\n",
      "(1368, 27, 66655)\n",
      "(1368, 27, 66655)\n",
      "(1368, 27, 66655)\n"
     ]
    }
   ],
   "source": [
    "order_of_vars = ['q', 'clwc', 'ciwc', 't', 'pa', 'zg', 'cc']\n",
    "data_dict = load_data(source='era5', days='all', order_of_vars=order_of_vars)\n",
    "\n",
    "TIMESTEPS, VLAYERS, HFIELDS = data_dict['q'].shape\n",
    "\n",
    "# Removing four upper-most levels\n",
    "for key in data_dict.keys():\n",
    "    data_dict[key] = data_dict[key][:, 4:].copy()\n",
    "\n",
    "# Data output\n",
    "data_output = data_dict['cc']\n",
    "del data_dict['cc']\n",
    "\n",
    "for key in data_dict.keys():\n",
    "    print(data_dict[key].shape)\n",
    "    assert data_dict[key].shape == data_dict[key].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f71e00a8-54b5-4840-ae17-bb43169651e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '~/bd1179_work/ERA5/hvcg_data/rh_z'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m all_npy_files \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m0\u001b[39m, VLAYERS\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m, HFIELDS))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Load all filenames in the folder containing the derivatives. The filenames are sorted chronologically.\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m npy_file_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m~/bd1179_work/ERA5/hvcg_data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)        \n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m npy_file_names:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Load three-hourly data and convert directly to float32\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     npy_file \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m~/bd1179_work/ERA5/hvcg_data/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m(folder,file), mmap_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '~/bd1179_work/ERA5/hvcg_data/rh_z'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "# Add rh\n",
    "T0 = 273.15\n",
    "r = 0.00263*data_dict['pa']*data_dict['q']*np.exp((17.67*(data_dict['t']-T0))/(data_dict['t']-29.65))**(-1)\n",
    "data_dict['rh'] = r\n",
    "\n",
    "# Add rh_z\n",
    "folder = 'rh_z'\n",
    "\n",
    "# Initialize all_npy_files with empty tensor\n",
    "all_npy_files = np.zeros((0, VLAYERS-4, HFIELDS))\n",
    "\n",
    "# Load all filenames in the folder containing the derivatives. The filenames are sorted chronologically.\n",
    "npy_file_names = sorted(os.listdir(os.path.join(os.environ['HOME'] + '/bd1179_work/ERA5/hvcg_data', folder)))        \n",
    "\n",
    "for file in npy_file_names:\n",
    "    # Load three-hourly data and convert directly to float32\n",
    "    npy_file = np.load(os.environ['HOME'] + '/bd1179_work/ERA5/hvcg_data/%s/%s'%(folder,file), mmap_mode='r')\n",
    "    npy_file = np.float32(npy_file[0::3].copy())\n",
    "    all_npy_files = np.concatenate((all_npy_files, npy_file), axis=0)\n",
    "data_dict[folder] = all_npy_files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4684930-7187-496a-beb4-212a39e71f19",
   "metadata": {},
   "source": [
    "**Reshaping and keeping only the relevant features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b42e2-8efe-4da9-9ace-9db49ebdc95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only the relevant features\n",
    "features = ['rh', 't', 'clwc', 'ciwc', 'rh_z']\n",
    "for key in features:\n",
    "    data_dict[key] = np.reshape(data_dict[key], -1)\n",
    "    \n",
    "data_output = np.reshape(data_output, -1)\n",
    "\n",
    "del data_dict['q']\n",
    "del data_dict['pa']\n",
    "del data_dict['zg']\n",
    "\n",
    "no_features = len(data_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edb6151-f4c7-45e9-b8f8-9278aeb1d10e",
   "metadata": {},
   "source": [
    "**Cast dict into ndarray**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1ed350-1625-4154-9f6f-37cdf0b54909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_array = np.zeros((data_dict['q'].size, len(data_dict.keys())), dtype=np.float32)\n",
    "\n",
    "k = 0\n",
    "data_array_not_T = []\n",
    "for key in features:\n",
    "    print(key)\n",
    "    data_array_not_T.append(np.reshape(data_dict[key], -1))\n",
    "    del data_dict[key]\n",
    "    k += 1\n",
    "\n",
    "# Convert into np array and transpose\n",
    "data_array = np.transpose(np.array(data_array_not_T, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3ee0ba-bdb7-4d5e-b0be-d0fcfff35a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update loc\n",
    "loc = {}\n",
    "for i in range(len(features)):\n",
    "    loc[features[i]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da5016d-7767-4185-b42c-808970b45bfc",
   "metadata": {},
   "source": [
    "**Remove condensate-free cells**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f67ea51-dd7e-4c28-8927-124b4db17a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already remove the regime with clw + cli = 0\n",
    "reg_not_0 = np.where(data_array[:, loc['clwc']] + data_array[:, loc['ciwc']] > 1e-20)[0]\n",
    "data_array = data_array[reg_not_0]\n",
    "data_output = data_output[reg_not_0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07efb27-fbfc-44e9-ae07-28fc3053b9a1",
   "metadata": {},
   "source": [
    "**Define the training/validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae4056c-899c-44f5-bc67-9a5066e27ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defines the training set\n",
    "T_subset_train = 10**6\n",
    "inds_train = np.random.randint(0, data_array.shape[0], T_subset_train)\n",
    "\n",
    "flattened_input_train = data_array[inds_train]\n",
    "flattened_output_train = data_output[inds_train]\n",
    "\n",
    "# Defines the validation set\n",
    "T_subset_valid = 10**6\n",
    "inds_valid = np.random.randint(0, data_array.shape[0], T_subset_valid)\n",
    "\n",
    "flattened_input_valid = data_array[inds_valid]\n",
    "flattened_output_valid = data_output[inds_valid]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2189db69-5e1e-40fa-a398-88be10382cd1",
   "metadata": {},
   "source": [
    "### Ablation Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150e3da5-c7ec-44bc-a516-de8c17a6f6d9",
   "metadata": {},
   "source": [
    "**Optimize coefficients in physical equation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c823bd5e-91a5-41e1-a7bf-6eb41f631403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See ~/workspace_icon-ml/symbolic_regression/finding_symmetries/pysr_results_dyamond_on_regimes/no_of_regimes_2/notes.txt\n",
    "def func(X, a_1,a_2,a_3,a_4,a_5,a_6,a_7,a_8,a_9,eps):\n",
    "    rh = X[:, loc['rh']] \n",
    "    ta = X[:, loc['t']] \n",
    "    clw = X[:, loc['clwc']] \n",
    "    cli = X[:, loc['ciwc']]\n",
    "    rh_z = X[:, loc['rh_z']]\n",
    "    \n",
    "    rh0 = 0.6025\n",
    "    ta0 = 257.06\n",
    "    \n",
    "    if np.abs(a_4) > 1e-5:\n",
    "        rh = np.maximum(rh, (rh0-a_2/a_4) - a_5/(2.*a_4)*(ta-ta0)**2)\n",
    "        \n",
    "    I1 = a_1 + a_2*(rh-rh0) + a_3*(ta-ta0) + a_4/2.*(rh-rh0)**2 + a_5/2.*(ta-ta0)**2*(rh-rh0)\n",
    "    I2 = a_6**3*(rh_z + 3.0/2*a_7)*rh_z**2\n",
    "    I3 = -1/(clw/a_8 + cli/a_9 + eps)\n",
    "    \n",
    "    return 100*(I1 + I2 + I3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f61aad-f586-4a08-9d4f-f30a21b373a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sci\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae8671f-6d71-4094-b471-a7724c7354a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(P, X,Y,force_zero=None):\n",
    "    '''\n",
    "        The objective function.\n",
    "    '''\n",
    "    a_1,a_2,a_3,a_4,a_5,a_6,a_7,a_8,a_9,eps = P\n",
    "    \n",
    "    # A way to remove terms using a list. Somehow I cannot use locals or exec here...\n",
    "    if force_zero == 'a_1': a_1 = 0\n",
    "    elif force_zero == 'a_2': a_2 = 0\n",
    "    elif force_zero == 'a_3': a_3 = 0\n",
    "    elif force_zero == 'a_4': a_4 = 0\n",
    "    elif force_zero == 'a_5': a_5 = 0\n",
    "    elif force_zero == 'a_6': a_6 = 0\n",
    "    elif force_zero == 'a_7': a_7 = 0\n",
    "    elif force_zero == 'a_8': a_8 = 0\n",
    "    elif force_zero == 'a_9': a_9 = 0\n",
    "    elif force_zero == 'eps': eps = 0\n",
    "            \n",
    "    train_preds = np.minimum(np.maximum(func(X, a_1,a_2,a_3,a_4,a_5,a_6,a_7,a_8,a_9,eps), 0), 100) \n",
    "    train_mse = np.mean((train_preds - Y)**2, dtype=np.float64)\n",
    "\n",
    "    return train_mse\n",
    "\n",
    "(a_1,a_2,a_3,a_4,a_5,a_6,a_7,a_8,a_9,eps) = (0.4435, 1.1593, -0.0145, 4.06, 0.0013176, 584.8036, 0.002, 1.1573e-6, 3.073e-7, 1.06)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7438c8b9-cc09-4f87-a6e3-cfb6b6ed0c3a",
   "metadata": {},
   "source": [
    "**Evaluate reduced equations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fc6fc8-eac9-43d5-8dfb-654d89238c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_mses = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d474b96-4781-45cd-af85-eedf55bc3bae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = [None,'a_1','a_2','a_3','a_4','a_5','a_6','a_7','a_8','a_9']\n",
    "\n",
    "for par_ind in range(len(parameters)):\n",
    "    force_zero = parameters[par_ind]\n",
    "\n",
    "    # Nelder-Mead gives me the same result\n",
    "    res_bfgs = minimize(objective, (a_1,a_2,a_3,a_4,a_5,a_6,a_7,a_8,a_9,eps), args=(flattened_input_train, flattened_output_train, force_zero), \\\n",
    "                   method='BFGS', options={'disp': True})\n",
    "\n",
    "    res_nm = minimize(objective, (a_1,a_2,a_3,a_4,a_5,a_6,a_7,a_8,a_9,eps), args=(flattened_input_train, flattened_output_train, force_zero), \\\n",
    "                   method='Nelder-Mead', options={'disp': True})\n",
    "\n",
    "    # Compute objective for both minima\n",
    "    valid_reg_mse_bfgs = objective(res_bfgs.x, flattened_input_valid, flattened_output_valid, force_zero)\n",
    "    valid_reg_mse_nm = objective(res_nm.x, flattened_input_valid, flattened_output_valid, force_zero)\n",
    "\n",
    "    valid_reg_mse = np.minimum(valid_reg_mse_bfgs, valid_reg_mse_nm)\n",
    "\n",
    "    print('On the entire dataset')\n",
    "    print('Valid MSE: %.5f'%valid_reg_mse)\n",
    "\n",
    "    # Add to dictionary\n",
    "    if force_zero == None:\n",
    "        valid_mses['full_eq'] = valid_reg_mse\n",
    "    else:      \n",
    "        valid_mses[force_zero] = valid_reg_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3a5dcb-8695-40dc-9bee-8d4960b85729",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/b/b309170/my_work/published_code/grundner23james_EquationDiscovery_CloudCover_addressing_reviews/sec6_physical_interpretation/ablation_study_new/ablation_study_era5_phys_seed_%d.json'%SEED, 'w') as file:\n",
    "    json.dump(valid_mses, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8fabb7-7dde-4f38-a064-36b2c26b5063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python399",
   "language": "python",
   "name": "python399"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting RH vs Cloud Cover**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ran with Python 3 environment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "import sys\n",
    "import sympy as sp\n",
    "\n",
    "sys.path.insert(0, '~/workspace_icon-ml/cloud_cover_parameterization')\n",
    "\n",
    "import tensorflow as tf\n",
    "import my_classes\n",
    "import time\n",
    "import json\n",
    "\n",
    "from my_classes import read_mean_and_std\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow import nn\n",
    "\n",
    "abspath = '~/workspace_icon-ml/symbolic_regression/evaluate_schemes/analyzing_eqns/v1/'\n",
    "\n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "matplotlib.use('PDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "output_path = '~/my_work/icon-ml_data/cloud_cover_parameterization/neighborhood_based_SR_DYAMOND'\n",
    "\n",
    "input_data = np.load(output_path + '/cloud_cover_input_dyamond.npy')\n",
    "output_data = np.load(output_path + '/cloud_area_output_dyamond.npy')\n",
    "\n",
    "# To locate variables\n",
    "features = ['hus', 'clw', 'cli', 'ta', 'pa', 'zg', 'fr_land', 'U', 'rh', 'ps', 'hus_z', 'hus_zz', 'clw_z', 'clw_zz', 'cli_z',\\\n",
    "                  'cli_zz', 'ta_z', 'ta_zz', 'pa_z', 'pa_zz', 'U_z', 'U_zz', 'rh_z', 'rh_zz']\n",
    "len(features)\n",
    "\n",
    "loc = {}\n",
    "for i in range(len(features)):\n",
    "    loc[features[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with random subset (the entire dataset takes too much memory)\n",
    "np.random.seed(10)\n",
    "rand_int = np.random.randint(0, input_data.shape[0], 10**8)\n",
    "\n",
    "input_data = input_data[rand_int]\n",
    "output_data = output_data[rand_int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "mean,std = read_mean_and_std('~/workspace_icon-ml/cloud_cover_parameterization/neighborhood_based_SR_DYAMOND/saved_models/cross_validation_neighborhood_based_sr_cl_area_fold_2.txt')\n",
    "\n",
    "input_data_scaled = (input_data - mean)/std\n",
    "\n",
    "all_features = ['hus', 'clw', 'cli', 'ta', 'pa', 'zg', 'fr_land', 'U', 'rh', 'ps', 'hus_z', 'hus_zz', 'clw_z', 'clw_zz', 'cli_z', 'cli_zz', 'ta_z', 'ta_zz', 'pa_z', 'pa_zz', 'U_z', 'U_zz', 'rh_z', 'rh_zz']\n",
    "\n",
    "loc_all = {}\n",
    "for i in range(len(all_features)):\n",
    "    loc_all[all_features[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best PySR equations\n",
    "with open('~/workspace_icon-ml/symbolic_regression/finding_symmetries/pysr_results_dyamond_on_regimes/no_of_regimes_2/optimized_eqns.json', 'r') as file:\n",
    "    pysr_eqns = json.load(file)\n",
    "    \n",
    "rh, ta, rh_z, cli, clw = sp.symbols('rh ta rh_z cli clw')\n",
    "x0, x1, x2, x3, x4 = sp.symbols('x0 x1 x2 x3 x4')\n",
    "    \n",
    "pysr_EQ1 = sp.lambdify((rh, ta, rh_z, cli, clw), pysr_eqns['EQ1']['Equation w.r.t. physical vars'])\n",
    "pysr_EQ4 = sp.lambdify((rh, ta, rh_z, cli, clw), pysr_eqns['EQ4']['Equation w.r.t. physical vars'])\n",
    "\n",
    "def pysr_EQ1_mod(rh, ta, rh_z, cli, clw):\n",
    "    # Artificially increase RH to ensure RH-constraint\n",
    "    (a,b,c,d) = (38.85954116, 42.70818472, 19.34746465, 1.11321032)\n",
    "    \n",
    "    x0 = (rh - mean[loc_all['rh']])/std[loc_all['rh']]\n",
    "    x1 = (ta - mean[loc_all['ta']])/std[loc_all['ta']]\n",
    "    \n",
    "    x0 = np.maximum(x0, 1/(2*c*d)*(-c*x1**2-a))\n",
    "    \n",
    "    rh = x0*std[loc_all['rh']] + mean[loc_all['rh']]\n",
    "    \n",
    "    return pysr_EQ1(rh, ta, rh_z, cli, clw)    \n",
    "    \n",
    "def pysr_EQ4_mod(rh, ta, rh_z, cli, clw):\n",
    "    # Artificially increase RH to ensure RH-constraint\n",
    "    (a,b,c,d) = (38.6562122, 43.53500518, 19.78403208, 1.13637902)\n",
    "    \n",
    "    x0 = (rh - mean[loc_all['rh']])/std[loc_all['rh']]\n",
    "    x1 = (ta - mean[loc_all['ta']])/std[loc_all['ta']]\n",
    "    \n",
    "    x0 = np.maximum(x0, 1/(2*c*d)*(-c*x1**2-a))\n",
    "    \n",
    "    rh = x0*std[loc_all['rh']] + mean[loc_all['rh']]\n",
    "    \n",
    "    return pysr_EQ4(rh, ta, rh_z, cli, clw)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load NN\n",
    "custom_objects = {}\n",
    "custom_objects['leaky_relu'] = nn.leaky_relu\n",
    "\n",
    "# SFS 24 (from workspace/cloud_cover_parameterization/neighborhood_based_SR_DYAMOND/saved_models/cross_validation_neighborhood_based_sr_cl_area_fold_2.h5)\n",
    "sfs_24_nn = load_model('~/workspace_icon-ml/cloud_cover_parameterization/neighborhood_based_SR_DYAMOND/saved_models/cross_validation_neighborhood_based_sr_cl_area_fold_2.h5', custom_objects)\n",
    "\n",
    "def b(x):\n",
    "    return np.minimum(np.maximum(x, 0), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add data PDPs to the plots!\n",
    "# Runs for 70s*len(X_vals)\n",
    "def find_closest_samples(X, X_vals, N):\n",
    "    '''\n",
    "        X [str]: The feature, for which we should not use the mean\n",
    "        X_vals [list(float)]: The values for the scaled! features (instead of the mean)\n",
    "        N [int]: The number of closest samples, that shall be in the output\n",
    "        returns: The indices of the N closest samples\n",
    "    '''\n",
    "    indices = np.zeros((input_data_scaled.shape[0], len(X_vals)))\n",
    "    \n",
    "    feats = ['rh', 'ta', 'rh_z', 'cli', 'clw']\n",
    "    feats.remove(X)\n",
    "    feat_inds = [loc[feat] for feat in feats]\n",
    "    s = np.sum(np.abs(input_data_scaled[:, feat_inds]), axis=1)\n",
    "    \n",
    "    for k in range(len(X_vals)):\n",
    "        indices[:, k] = s + np.abs(input_data_scaled[:, loc[X]] - X_vals[k])\n",
    "        \n",
    "    sorted_inds = np.argsort(indices, axis=0) # Takes most of the time\n",
    "    return sorted_inds[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_mean = np.mean(input_data[:, loc['ta']])\n",
    "rh_z_mean = np.mean(input_data[:, loc['rh_z']])\n",
    "cli_mean = np.mean(input_data[:, loc['cli']])\n",
    "clw_mean = np.mean(input_data[:, loc['clw']])\n",
    "rh_mean = np.mean(input_data[:, loc['rh']])\n",
    "\n",
    "ta_std = np.mean(input_data[:, loc['ta']])\n",
    "rh_z_std = np.mean(input_data[:, loc['rh_z']])\n",
    "cli_std = np.mean(input_data[:, loc['cli']])\n",
    "clw_std = np.mean(input_data[:, loc['clw']])\n",
    "rh_std = np.mean(input_data[:, loc['rh']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Relative Humidity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.66198778152466"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Runs for 80 mins, with all data! For 17 minutes with 10**8 samples.\n",
    "rh_vals = np.linspace(np.min(input_data[:, loc['rh']]), 1.1, 40)\n",
    "\n",
    "# sample_indices = find_closest_samples('rh', (rh_vals - rh_mean)/rh_std, 100) # The Bottleneck! Scales with O(len(rh_vals)).\n",
    "# output_mean_data = [np.mean(output_data[sample_indices[:, k]]) for k in range(len(rh_vals))]\n",
    "\n",
    "output_sfs_nn_24 = []\n",
    "for rh in rh_vals:\n",
    "    input_arr = np.expand_dims((np.mean(input_data, axis=0) - mean)/std, 0)\n",
    "    input_arr[0, loc['rh']] = (rh - mean[loc['rh']])/std[loc['rh']]\n",
    "    pred = b(sfs_24_nn.predict(input_arr))\n",
    "    output_sfs_nn_24.append(pred)\n",
    "\n",
    "# To be able to save the numbers\n",
    "plot_values = {}\n",
    "plot_values['RH values'] = list(rh_vals)\n",
    "for eq_num in ['1', '1_mod', '4', '4_mod']:\n",
    "    plot_values['pysr_EQ%s'%eq_num] = list(b(locals()['pysr_EQ%s'%eq_num](rh_vals, ta_mean, rh_z_mean, cli_mean, clw_mean)))\n",
    "plot_values['sfs_nn_24'] = list(np.float64(np.array(output_sfs_nn_24)[:,0,0]))\n",
    "# plot_values['data_mean'] = list(np.float64(output_mean_data))\n",
    "    \n",
    "# plt.plot(rh_vals, plot_values['pysr_EQ1'], color=CB_color_cycle[0])\n",
    "# plt.plot(rh_vals, plot_values['pysr_EQ1_mod'], color=CB_color_cycle[1])\n",
    "plt.plot(rh_vals, plot_values['pysr_EQ4'], color=CB_color_cycle[0])\n",
    "plt.plot(rh_vals, plot_values['pysr_EQ4_mod'], color=CB_color_cycle[1])\n",
    "plt.plot(rh_vals, plot_values['sfs_nn_24'], color=CB_color_cycle[2])\n",
    "# plt.plot(rh_vals, plot_values['data_mean'], color='black')\n",
    "plt.title('b) $f_{mean}$(RH)')\n",
    "# plt.legend(['PySR equation', 'PySR eq., PC$_3$ enforced', 'SFS NN 24', 'DYAMOND cl_area'])\n",
    "plt.legend(['PySR equation', 'PySR eq., PC$_3$ enforced', 'SFS24 NN'])\n",
    "plt.xlabel('Relative Humidity')\n",
    "plt.ylabel('Cloud Cover [%]')\n",
    "plt.savefig('RH_vs_cl_area_mod.pdf')\n",
    "\n",
    "# Restore default figsize\n",
    "plt.close()\n",
    "plt.clf()\n",
    "plt.figure()\n",
    "\n",
    "time.time() - t0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (based on the module python3/2022.01)",
   "language": "python",
   "name": "python3_2022_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

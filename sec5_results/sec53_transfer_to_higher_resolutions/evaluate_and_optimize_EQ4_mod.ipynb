{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f72e7804-7edc-4130-aa10-b2a5b4e5ba6e",
   "metadata": {},
   "source": [
    "### Evaluate the PySR equation on higher-res DYAMOND data\n",
    "\n",
    "- Data path: /home/b/b309170/bd1179_work/DYAMOND/hcg_data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae7838b-c3ee-46f2-9a01-217d483dbe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# subset_exp = int(sys.argv[1])\n",
    "# subset_exp = 2\n",
    "# number_horizontal_locations = 10**subset_exp\n",
    "tl_bool = True\n",
    "\n",
    "sys.path.insert(0, os.environ['HOME'] + '/my_work/published_code/grundner23james_EquationDiscovery_CloudCover_addressing_reviews/sec2_data/')\n",
    "import my_classes\n",
    "from my_classes import read_mean_and_std\n",
    "from my_classes import load_data\n",
    "from functions import append_dict_to_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f454881a-f4c8-4db7-8f38-dee94accfbab",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79c6320b-e34b-4b8c-9031-12ffa5d7c887",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b/b309170/my_work/published_code/grundner23james_EquationDiscovery_CloudCover_addressing_reviews/sec2_data/my_classes.py:403: FutureWarning: In xarray version 0.15 the default behaviour of `open_mfdataset`\n",
      "will change. To retain the existing behavior, pass\n",
      "combine='nested'. To use future default behavior, pass\n",
      "combine='by_coords'. See\n",
      "http://xarray.pydata.org/en/stable/combining.html#combining-multi\n",
      "\n",
      "  DS = xr.open_mfdataset(path+'/zg/zg*')\n",
      "/home/b/b309170/my_work/Miniconda3/envs/clouds/lib/python3.7/site-packages/xarray/backends/api.py:933: FutureWarning: The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset`) to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in future, please use the new\n",
      "`combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  from_openmfds=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q\n",
      "qc\n",
      "qi\n",
      "t\n",
      "pres\n",
      "clc\n",
      "(80, 60, 327680)\n",
      "(80, 60, 327680)\n",
      "(80, 60, 327680)\n",
      "(80, 60, 327680)\n",
      "(80, 60, 327680)\n",
      "(80, 60, 327680)\n",
      "(80, 60, 327680)\n",
      "(80, 60, 327680)\n",
      "(80, 60, 327680)\n",
      "(80, 60, 327680)\n",
      "(80, 60, 327680)\n",
      "(80, 60, 327680)\n",
      "(80, 60, 327680)\n",
      "(80, 60, 327680)\n"
     ]
    }
   ],
   "source": [
    "order_of_vars = ['q', 'qc', 'qi', 't', 'pres', 'zg', 'clc']\n",
    "\n",
    "data_path = '/home/b/b309170/bd1179_work/DYAMOND/hcg_data_r2b6'\n",
    "data_dict = load_data(source='split_by_var_name', days='all', vert_interp=False, \\\n",
    "                      resolution='R02B06', order_of_vars=order_of_vars, path=data_path)\n",
    "\n",
    "TIMESTEPS, VLAYERS, HFIELDS = data_dict['q'].shape\n",
    "\n",
    "data_dict['zg'] = np.repeat(np.expand_dims(data_dict['zg'].T, axis=0), TIMESTEPS, axis=0)\n",
    "\n",
    "# Only keep the lowest 60 levels (ensure that all fields have the same vertical grid)\n",
    "for key in data_dict.keys():\n",
    "    data_dict[key] = data_dict[key][:, -60:].copy()\n",
    "    print(data_dict[key].shape)\n",
    "\n",
    "for key in data_dict.keys():\n",
    "    print(data_dict[key].shape)\n",
    "    assert data_dict[key].shape == data_dict[key].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b1a97cb-ca8b-4cf1-ac64-5dd4a49d6a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 58, 327680)\n",
      "(80, 58, 327680)\n",
      "(80, 58, 327680)\n",
      "(80, 58, 327680)\n",
      "(80, 58, 327680)\n",
      "(80, 58, 327680)\n",
      "(80, 58, 327680)\n",
      "(80, 58, 327680)\n",
      "(80, 58, 327680)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "# Add rh\n",
    "T0 = 273.15\n",
    "r = 0.00263*data_dict['pres']*data_dict['q']*np.exp((17.67*(data_dict['t']-T0))/(data_dict['t']-29.65))**(-1)\n",
    "data_dict['rh'] = r\n",
    "\n",
    "# Update\n",
    "TIMESTEPS, VLAYERS, HFIELDS = data_dict['q'].shape\n",
    "\n",
    "# Add rh_z\n",
    "data_dict['rh_z'] = (r[:, :-1] - r[:, 1:])/(data_dict['zg'][:, :-1] - data_dict['zg'][:, 1:])\n",
    "\n",
    "# Only keep the lowest 58 levels (ensure that all fields have the same vertical grid)\n",
    "for key in data_dict.keys():\n",
    "    data_dict[key] = data_dict[key][:, -58:].copy()\n",
    "    print(data_dict[key].shape)\n",
    "    \n",
    "# Data output\n",
    "data_output = 100*data_dict['clc']\n",
    "del data_dict['clc']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae7f585-0a81-4a97-89b9-eb3b48eff176",
   "metadata": {},
   "source": [
    "**Reshaping and keeping only the relevant features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02554fbd-a45a-48a8-a130-e9dae58174c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only the relevant features\n",
    "features = ['rh', 't', 'qc', 'qi', 'rh_z']\n",
    "for key in features:\n",
    "    data_dict[key] = np.reshape(data_dict[key], -1)\n",
    "    \n",
    "data_output = np.reshape(data_output, -1)\n",
    "\n",
    "del data_dict['q']\n",
    "del data_dict['pres']\n",
    "del data_dict['zg']\n",
    "\n",
    "no_features = len(data_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a85c4cd-eb04-42e6-b93f-8e9d5e56eb2e",
   "metadata": {},
   "source": [
    "**Cast dict into ndarray**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c0dbaf8-d1de-4334-9035-0a6b6e4c94f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rh\n",
      "t\n",
      "qc\n",
      "qi\n",
      "rh_z\n"
     ]
    }
   ],
   "source": [
    "# data_array = np.zeros((data_dict['q'].size, len(data_dict.keys())), dtype=np.float32)\n",
    "\n",
    "k = 0\n",
    "data_array_not_T = []\n",
    "for key in features:\n",
    "    print(key)\n",
    "    data_array_not_T.append(np.reshape(data_dict[key], -1))\n",
    "    del data_dict[key]\n",
    "    k += 1\n",
    "\n",
    "# Convert into np array and transpose\n",
    "data_array = np.transpose(np.array(data_array_not_T, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f8caec0-e181-4e8a-bc20-b31b952fb185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update loc\n",
    "loc = {}\n",
    "for i in range(len(features)):\n",
    "    loc[features[i]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f9dda-8c13-47a6-ad1e-caf0b9924257",
   "metadata": {},
   "source": [
    "**Normalize the features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43603af8-79bb-4ffb-a859-987be37681b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_possible_features = ['hus', 'clw', 'cli', 'ta', 'pa', 'zg', 'fr_land', 'U', 'rh', 'ps', 'hus_z', 'hus_zz', 'clw_z', 'clw_zz', 'cli_z',\\\n",
    "            'cli_zz', 'ta_z', 'ta_zz', 'pa_z', 'pa_zz', 'U_z', 'U_zz', 'rh_z', 'rh_zz']\n",
    "loc = {}\n",
    "for i in range(len(all_possible_features)):\n",
    "    loc[all_possible_features[i]] = i\n",
    "features = ['rh', 'ta', 'clw', 'cli', 'rh_z']\n",
    "\n",
    "# Scale the data\n",
    "mean_all = [4.12205844e-03,2.25493498e-05,3.38180032e-06,2.57065512e+02,6.00030443e+04,5.64080139e+03,2.35046400e-01,1.32776682e+01,6.02512234e-01,9.86270417e+04,-1.27545273e-06,-4.02484958e-10,1.65204582e-08,-4.34660202e-11,4.29441131e-10,-1.82817316e-12,-4.68742483e-03,-7.54899040e-07,-7.51544542e+00,-1.06989723e-04,1.65615172e-03,-9.27604679e-06,-4.76200071e-05,-1.32246548e-07]\n",
    "std_all = [5.07648249e-03,5.69702638e-05,1.01308124e-05,3.00533874e+01,3.12514292e+04,5.66963918e+03,4.11184302e-01,1.11389888e+01,3.32494615e-01,6.24039256e+03,2.03179260e-06,1.17041141e-08,1.33311867e-07,1.42840744e-09,6.73384546e-09,5.07424672e-11,5.82875686e-03,6.34826092e-05,3.53136052e+00,1.13215264e-02,6.62892130e-03,6.08144307e-05,2.58065098e-04,2.49552692e-06]\n",
    "\n",
    "mean = np.concatenate([np.expand_dims(mean_all[loc[sel_var]], axis=0) for sel_var in features], axis = 0)\n",
    "std = np.concatenate([np.expand_dims(std_all[loc[sel_var]], axis=0) for sel_var in features], axis = 0)\n",
    "\n",
    "# Work with scaled training folds\n",
    "data_scaled = (data_array - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51702441-2dbb-4e54-ab31-796a587b2fb7",
   "metadata": {},
   "source": [
    "Optimize coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26e734a3-580a-48e4-b2c4-a891a42b5685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See ~/symbolic_regression/finding_symmetries/pysr_results_dyamond_on_regimes/optimize_coefs_EQ4.ipynb\n",
    "def func(X, a,b,c,d,e,f,g,h,i,j):\n",
    "    x0 = X[:, 0] \n",
    "    x1 = X[:, 1] \n",
    "    x2 = X[:, 2] \n",
    "    x3 = X[:, 3]\n",
    "    x4 = X[:, 4]\n",
    "    \n",
    "    # Modified to always satisfy RH-constraint\n",
    "    x0 = np.maximum(x0, 1/(2*c*d)*(-c*x1**2-a))\n",
    "    \n",
    "    return a*x0 - b*x1 + c*x0*(d*x0 + x1**2) + x4**2*(e*x4 + f) + g - h/(x2 + i*x3 + j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f1fdcef-6f16-45f7-a22c-17e90674665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(P, X,Y):\n",
    "    '''\n",
    "        The objective function.\n",
    "    '''\n",
    "    a,b,c,d,e,f,g,h,i,j = P\n",
    "    train_preds = np.minimum(np.maximum(func(X, a,b,c,d,e,f,g,h,i,j), 0), 100)\n",
    "    train_mse = np.mean((train_preds - Y)**2, dtype=np.float64)\n",
    "\n",
    "    return train_mse\n",
    "\n",
    "(a,b,c,d,e,f,g,h,i,j) = (38.6562122, 43.53500518, 19.78403208, 1.13637902, 0.35299939,\\\n",
    "                         4.04888686, 44.21730274, 2.03128527, 0.66971589, 0.6409019)\n",
    "\n",
    "# Compute the MSE and terminate if not tl_bool\n",
    "P = (a,b,c,d,e,f,g,h,i,j)\n",
    "mse = objective(P, data_scaled, data_output)\n",
    "var = np.var(data_output)\n",
    "r2 = 1-mse/var\n",
    "\n",
    "results = {}\n",
    "parent_key = 'pysr_EQ4'\n",
    "results[parent_key] = {}\n",
    "results[parent_key]['MSE'] = mse\n",
    "results[parent_key]['R2'] = r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016d71c9-c056-49a4-95e4-e67be9fddadb",
   "metadata": {},
   "source": [
    "**Save results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5128a4ef-6097-485d-9a13-cccf601a5cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New file created or first entry added\n"
     ]
    }
   ],
   "source": [
    "# Dump results\n",
    "append_dict_to_json(results, os.environ['HOME'] + '/my_work/published_code/grundner23james_EquationDiscovery_CloudCover_addressing_reviews/sec5_results/transfer_to_higher_resolutions/results/pysr_eq4_r2b6.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clouds",
   "language": "python",
   "name": "clouds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

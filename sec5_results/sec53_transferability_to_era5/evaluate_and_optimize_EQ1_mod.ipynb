{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11f30507-e4a1-46de-af0d-f61255e00ab7",
   "metadata": {},
   "source": [
    "Executed through ~scripts/run_era5_evalute_and_transfer_learn_1.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48f22d14-ab2e-452f-9ff8-8e8ee673bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ran with 240GB (see evaluate_and_optimize_EQ1_mod-checkmem.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f87e2ed-1fea-4c72-a990-e5c73e861aa3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msympy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m subset_exp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# subset_exp = 2\u001b[39;00m\n\u001b[1;32m     11\u001b[0m number_horizontal_locations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msubset_exp\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '-f'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import sympy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "subset_exp = int(sys.argv[1])\n",
    "# subset_exp = 2\n",
    "number_horizontal_locations = 10**subset_exp\n",
    "tl_bool = True\n",
    "\n",
    "sys.path.insert(0, '~/workspace_icon-ml/cloud_cover_parameterization/')\n",
    "import my_classes\n",
    "from my_classes import load_data\n",
    "\n",
    "sys.path.insert(0, '~/workspace_icon-ml/symbolic_regression/')\n",
    "from functions import add_derivatives\n",
    "from functions import append_dict_to_json\n",
    "\n",
    "# era5\n",
    "evaluate_on = 'era5'\n",
    "\n",
    "SEED = int(sys.argv[2])\n",
    "\n",
    "num_cells = int(sys.argv[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2624fe28-4e22-4f3e-a9f8-028ec7fa1106",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dafce0-8c7a-4cc9-a8b9-45d5184005ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_of_vars = ['q', 'clwc', 'ciwc', 't', 'pa', 'zg', 'cc']\n",
    "data_dict = load_data(source='era5', days='all', order_of_vars=order_of_vars)\n",
    "\n",
    "TIMESTEPS, VLAYERS, HFIELDS = data_dict['q'].shape\n",
    "\n",
    "# Removing four upper-most levels\n",
    "for key in data_dict.keys():\n",
    "    data_dict[key] = data_dict[key][:, 4:].copy()\n",
    "\n",
    "# Data output\n",
    "data_output = data_dict['cc']\n",
    "del data_dict['cc']\n",
    "\n",
    "for key in data_dict.keys():\n",
    "    print(data_dict[key].shape)\n",
    "    assert data_dict[key].shape == data_dict[key].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5380f39e-3564-4e1c-924e-fa7baedb472e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "# Add rh\n",
    "T0 = 273.15\n",
    "r = 0.00263*data_dict['pa']*data_dict['q']*np.exp((17.67*(data_dict['t']-T0))/(data_dict['t']-29.65))**(-1)\n",
    "data_dict['rh'] = r\n",
    "\n",
    "# Add rh_z\n",
    "from contextlib import contextmanager\n",
    "import multiprocessing as mlp\n",
    "import gc\n",
    "\n",
    "# Add rh_z\n",
    "folder = 'rh_z'\n",
    "\n",
    "# Initialize all_npy_files with empty tensor\n",
    "all_npy_files = np.zeros((0, VLAYERS-4, HFIELDS))\n",
    "\n",
    "# Load all filenames in the folder containing the derivatives. The filenames are sorted chronologically.\n",
    "npy_file_names = sorted(os.listdir(os.path.join('~/bd1179_work/ERA5/hvcg_data', folder)))        \n",
    "\n",
    "for file in npy_file_names:\n",
    "    # Load three-hourly data and convert directly to float32\n",
    "    npy_file = np.load('~/bd1179_work/ERA5/hvcg_data/%s/%s'%(folder,file), mmap_mode='r')\n",
    "    npy_file = np.float32(npy_file[0::3].copy())\n",
    "    all_npy_files = np.concatenate((all_npy_files, npy_file), axis=0)\n",
    "data_dict[folder] = all_npy_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e4c952-5132-4b15-a909-4a0dc145ff9b",
   "metadata": {},
   "source": [
    "**Reshaping and keeping only the relevant features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8069bbad-9136-4ff5-9655-3dd9f7ebc969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only the relevant features\n",
    "features = ['rh', 't', 'clwc', 'ciwc', 'rh_z']\n",
    "for key in features:\n",
    "    data_dict[key] = np.reshape(data_dict[key], -1)\n",
    "    \n",
    "data_output = np.reshape(data_output, -1)\n",
    "\n",
    "del data_dict['q']\n",
    "del data_dict['pa']\n",
    "del data_dict['zg']\n",
    "\n",
    "no_features = len(data_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5ea2e1-14ba-4591-b811-487270a821fc",
   "metadata": {},
   "source": [
    "**Cast dict into ndarray**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3294c70-7964-4213-8601-7b6e67cb2b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_array = np.zeros((data_dict['q'].size, len(data_dict.keys())), dtype=np.float32)\n",
    "\n",
    "k = 0\n",
    "data_array_not_T = []\n",
    "for key in features:\n",
    "    print(key)\n",
    "    data_array_not_T.append(np.reshape(data_dict[key], -1))\n",
    "    del data_dict[key]\n",
    "    k += 1\n",
    "\n",
    "# Convert into np array and transpose\n",
    "data_array = np.transpose(np.array(data_array_not_T, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744384a9-b48b-4e29-b171-1b948ff799b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update loc\n",
    "loc = {}\n",
    "for i in range(len(features)):\n",
    "    loc[features[i]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9110c03e-62c9-49aa-b126-9b564394069a",
   "metadata": {},
   "source": [
    "**Pick the subset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64c1d6c-799c-490f-af89-d321f7ab72a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.seed(SEED)\n",
    "subset = np.random.randint(0, HFIELDS, number_horizontal_locations)\n",
    "# Convert to regular int to make check_sum JSON serializable\n",
    "check_sum = int(np.sum(subset))\n",
    "\n",
    "# Collecting all grid cell indices for the horizontal fields given by subset\n",
    "Z = np.zeros((TIMESTEPS, 27, HFIELDS), dtype=int)\n",
    "for k in range(HFIELDS):\n",
    "    Z[:,:,k] = k\n",
    "Z_res = np.reshape(Z, -1)\n",
    "subset_inds = np.concatenate([np.where(Z_res == s)[0] for s in subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358bf73b-7a9c-495b-b59e-6c44eda7d0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = data_array[subset_inds[:num_cells]] #num_hours*27\n",
    "train_output = data_output[subset_inds[:num_cells]] #num_hours*27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b977761d-7894-4a9b-a6eb-983321f540ae",
   "metadata": {},
   "source": [
    "**Already remove the regime with clw + cli = 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a94f27-da39-4411-9bf0-d139e8fc4c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_0 = np.where(data_array[:, loc['clwc']] + data_array[:, loc['ciwc']] <= 1e-20)[0]\n",
    "reg_not_0 = np.where(data_array[:, loc['clwc']] + data_array[:, loc['ciwc']] > 1e-20)[0]\n",
    "\n",
    "# Relevant values to compute final MSE/R2-scores\n",
    "mse_reg_0 = np.mean(data_output[reg_0]**2)\n",
    "len_reg_0 = len(reg_0)\n",
    "len_reg_not_0 = len(reg_not_0)\n",
    "len_data_output = len(data_output)\n",
    "var_data_output = np.var(data_output)\n",
    "\n",
    "data_array = data_array[reg_not_0].copy()\n",
    "data_output = data_output[reg_not_0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc43c48c-73c3-4082-b124-8e098766f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mse_reg_0)\n",
    "print(data_array.shape)\n",
    "print(data_output.shape)\n",
    "\n",
    "# Should be 338023\n",
    "len_reg_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5711b1-f92c-47db-bef5-f162a9559355",
   "metadata": {},
   "source": [
    "**Normalize the features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d119dc-7b3a-4fa0-974c-a1b755b7b40b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_possible_features = ['hus', 'clw', 'cli', 'ta', 'pa', 'zg', 'fr_land', 'U', 'rh', 'ps', 'hus_z', 'hus_zz', 'clw_z', 'clw_zz', 'cli_z',\\\n",
    "            'cli_zz', 'ta_z', 'ta_zz', 'pa_z', 'pa_zz', 'U_z', 'U_zz', 'rh_z', 'rh_zz']\n",
    "loc = {}\n",
    "for i in range(len(all_possible_features)):\n",
    "    loc[all_possible_features[i]] = i\n",
    "features = ['rh', 'ta', 'clw', 'cli', 'rh_z']\n",
    "\n",
    "# Scale the data\n",
    "mean_all = [4.12205844e-03,2.25493498e-05,3.38180032e-06,2.57065512e+02,6.00030443e+04,5.64080139e+03,2.35046400e-01,1.32776682e+01,6.02512234e-01,9.86270417e+04,-1.27545273e-06,-4.02484958e-10,1.65204582e-08,-4.34660202e-11,4.29441131e-10,-1.82817316e-12,-4.68742483e-03,-7.54899040e-07,-7.51544542e+00,-1.06989723e-04,1.65615172e-03,-9.27604679e-06,-4.76200071e-05,-1.32246548e-07]\n",
    "std_all = [5.07648249e-03,5.69702638e-05,1.01308124e-05,3.00533874e+01,3.12514292e+04,5.66963918e+03,4.11184302e-01,1.11389888e+01,3.32494615e-01,6.24039256e+03,2.03179260e-06,1.17041141e-08,1.33311867e-07,1.42840744e-09,6.73384546e-09,5.07424672e-11,5.82875686e-03,6.34826092e-05,3.53136052e+00,1.13215264e-02,6.62892130e-03,6.08144307e-05,2.58065098e-04,2.49552692e-06]\n",
    "\n",
    "mean = np.concatenate([np.expand_dims(mean_all[loc[sel_var]], axis=0) for sel_var in features], axis = 0)\n",
    "std = np.concatenate([np.expand_dims(std_all[loc[sel_var]], axis=0) for sel_var in features], axis = 0)\n",
    "\n",
    "# Work with scaled training folds\n",
    "data_scaled = (data_array - mean)/std\n",
    "train_input = (train_input - mean)/std\n",
    "\n",
    "del data_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51702441-2dbb-4e54-ab31-796a587b2fb7",
   "metadata": {},
   "source": [
    "Optimize coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e734a3-580a-48e4-b2c4-a891a42b5685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# symbolic_regression/finding_symmetries/pysr_results_dyamond_on_regimes/no_of_regimes_2/notes.txt\n",
    "def func(X, a,b,c,d,e,f,g,h,i):\n",
    "    # X = ['rh', 't', 'clwc', 'ciwc', 'rh_z']\n",
    "    x0 = X[:, 0] \n",
    "    x1 = X[:, 1] \n",
    "    x2 = X[:, 2] \n",
    "    x3 = X[:, 3]\n",
    "    x4 = X[:, 4]\n",
    "    \n",
    "    # Modified to always satisfy RH-constrain\n",
    "    x0 = np.maximum(x0, 1/(2*c*d)*(-c*x1**2-a))\n",
    "    \n",
    "    return a*x0 - b*x1 + c*x0*(d*x0 + x1**2) + e*x4**2 + f - g/(x2 + h*x3 + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1685e5-d5ee-4ea7-b4e5-af0566792377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sci\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1fdcef-6f16-45f7-a22c-17e90674665e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(P, X,Y):\n",
    "    '''\n",
    "        The objective function.\n",
    "    '''\n",
    "    a,b,c,d,e,f,g,h,i = P\n",
    "    train_preds = np.minimum(np.maximum(func(X, a,b,c,d,e,f,g,h,i), 0), 100)\n",
    "    train_mse = np.mean((train_preds - Y)**2, dtype=np.float64)\n",
    "    return train_mse\n",
    "\n",
    "(a,b,c,d,e,f,g,h,i) = [38.85954116, 42.70818472, 19.34746465, 1.11321032, 2.36741444,\\\n",
    "                       44.99763015, 1.90033063, 0.65718667, 0.63587944]\n",
    "if tl_bool:\n",
    "    res = minimize(objective, (a,b,c,d,e,f,g,h,i), args=(train_input, train_output), \\\n",
    "                   method='Nelder-Mead', options={'disp': True})\n",
    "else:\n",
    "    # Compute the MSE and terminate if not tl_bool\n",
    "    P = (a,b,c,d,e,f,g,h,i)\n",
    "    mse_reg_1 = objective(P, data_scaled, data_output)\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    mse_new_total = (mse_reg_0*len_reg_0 + mse_reg_1*len_reg_not_0)/len_data_output\n",
    "    r2_new_total = 1 - mse_new_total/var_data_output\n",
    "\n",
    "    print(mse_new_total, r2_new_total)\n",
    "\n",
    "    parent_key = 'pysr_EQ1_no_tl'\n",
    "    results[parent_key] = {}\n",
    "    results[parent_key]['MSE'] = mse_new_total\n",
    "    results[parent_key]['R2'] = r2_new_total\n",
    "    results[parent_key]['Coefficients'] = list(res.x)\n",
    "    # Should be the same for all runs\n",
    "    results[parent_key]['Check_sum'] = check_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "373a1caf-7c49-4937-8e50-11f244f3a26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.93925530e+00  1.40195085e-02  9.24687637e-01  6.07912348e+01\n",
      "  1.38495251e+02  2.76480640e+01 -4.04303333e-01  1.07719122e+00\n",
      "  1.32919169e-01 -1.77971834e+00  1.58883122e+02  2.48770600e+01]\n"
     ]
    }
   ],
   "source": [
    "print(res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "477e8323-9b7f-4b59-894c-924eabe5336f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.94, 0.01, 0.92, 60.79, 138.5, 27.65, -0.4, 1.08, 0.13, -1.78, 158.88, 24.88]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.round(res.x, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7878720f-5901-44d6-b696-efa29667c02b",
   "metadata": {},
   "source": [
    "New values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03bebb8e-081a-4087-9ec8-0ef5b6357eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_reg_1 = objective(res.x, data_scaled, data_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "566611fa-2b82-4d5e-89e1-6d8ee94c8b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688.7440801766825 -1.1178964262207782\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "mse_new_total = (mse_reg_0*len_reg_0 + mse_reg_1*len_reg_not_0)/len_data_output\n",
    "r2_new_total = 1 - mse_new_total/var_data_output\n",
    "\n",
    "print(mse_new_total, r2_new_total)\n",
    "\n",
    "parent_key = 'pysr_EQ1_tl_%d_num_cells_%d_seed_%d'%(subset_exp,num_cells,SEED)\n",
    "results[parent_key] = {}\n",
    "results[parent_key]['MSE'] = mse_new_total\n",
    "results[parent_key]['R2'] = r2_new_total\n",
    "results[parent_key]['Coefficients'] = list(res.x)\n",
    "# Should be the same for all runs\n",
    "results[parent_key]['Check_sum'] = check_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec79f4a-7f92-4889-81bf-6f09cecee4da",
   "metadata": {},
   "source": [
    "**Save results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c0e3ae-f60f-4f7e-9720-c35edf47b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump results\n",
    "append_dict_to_json(results, '~/workspace_icon-ml/symbolic_regression/evaluate_schemes/on_era5/results/era5_1979-2021/era5_tuned_pysr_EQ1_mod.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bf1eb8f-0919-449c-9b65-40cb242f5281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(P,X):\n",
    "#     '''\n",
    "#         The objective function.\n",
    "#     '''\n",
    "#     a,b,c,d,e,f,g,h,i = P\n",
    "#     preds = [np.minimum(np.maximum(func(X[k_ind], a,b,c,d,e,f,g,h,i), 0), 100) for k_ind in range(X.shape[0])]\n",
    "\n",
    "#     return preds\n",
    "\n",
    "# predict(res.x, data_scaled)\n",
    "\n",
    "# plt.hist(data_output,bins=100, histtype='step', color='k')\n",
    "# plt.hist(predict(res.x, data_scaled),bins=100, histtype='step')\n",
    "\n",
    "# plt.yscale('log')\n",
    "# plt.legend(['ERA5', 'Eq. 1'])\n",
    "# plt.savefig('~/workspace_icon-ml/symbolic_regression/evaluate_schemes/on_era5/results/era5_1979-2021/era5_tuned_pysr_EQ1_mod.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c5df8b-a2c5-421f-bafa-6c4c588b3363",
   "metadata": {},
   "source": [
    "Original values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4de357ba-30d4-4a6d-a3c1-98e876634f13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mse_reg_1 = objective((1,1,0.77,41.39,20.69,20.69,0.66,0.53,0.35,0.23,60.6,3.44), data_scaled, data_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b19c405-3c78-4e9b-9e16-7e086561c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse_orig_total = (mse_reg_0*len_reg_0 + mse_reg_1*len_reg_not_0)/len_data_output\n",
    "# r2_orig_total = 1 - mse_orig_total/var_data_output\n",
    "\n",
    "# print(mse_orig_total, r2_orig_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422b8859-b578-488c-beb1-33b2973fd118",
   "metadata": {},
   "source": [
    "**Is the output of the objective function the same as in evaluate_pysr_schemes.ipynb? [objective]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42c31dd8-1fea-4167-ab0a-ef72b8f2ff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The output should be 52.99172553\n",
    "# X = np.zeros((1, 5))\n",
    "# [np.minimum(np.maximum(func(X[k_ind], a,b,c,d,e,f,g,h,i), 0), 100) for k_ind in range(X.shape[0])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python399",
   "language": "python",
   "name": "python399"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

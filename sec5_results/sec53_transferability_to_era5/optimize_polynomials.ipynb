{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1badcaf4-76d5-44ba-92c9-f5596572ff4c",
   "metadata": {},
   "source": [
    "Need to evaluate deg = 3, no_features = 2,3,4,5,6.\n",
    "\n",
    "Executed through /home/b/b309170/scripts/run_era5_evalute_and_transfer_learn_6.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef151e0c-f730-4cd2-ad76-c97b21060abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With native Python3 environment -- It takes around 12 minutes to evaluate one day\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import sympy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy as sci\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "sys.path.insert(0, '/home/b/b309170/workspace_icon-ml/cloud_cover_parameterization/')\n",
    "import my_classes\n",
    "from my_classes import load_data\n",
    "\n",
    "sys.path.insert(0, '/home/b/b309170/workspace_icon-ml/symbolic_regression/')\n",
    "from functions import append_dict_to_json\n",
    "\n",
    "subset_exp = int(sys.argv[1])\n",
    "number_horizontal_locations = 10**subset_exp\n",
    "\n",
    "tl_bool = True\n",
    "SEED = int(sys.argv[2])\n",
    "\n",
    "num_hours = int(sys.argv[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d564c1cb-776c-4354-b07c-81fefb588a99",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b73dc07-1c12-41bf-b0de-757f4ca8d1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q\n",
      "clwc\n",
      "ciwc\n",
      "t\n",
      "pa\n",
      "cc\n"
     ]
    }
   ],
   "source": [
    "order_of_vars = ['q', 'clwc', 'ciwc', 't', 'pa', 'zg', 'cc']\n",
    "data_dict = load_data(source='era5', days='all', order_of_vars=order_of_vars)\n",
    "\n",
    "TIMESTEPS, VLAYERS, HFIELDS = data_dict['q'].shape\n",
    "\n",
    "# Removing four upper-most levels\n",
    "for key in data_dict.keys():\n",
    "    data_dict[key] = data_dict[key][:, 4:].copy()\n",
    "\n",
    "# Data output\n",
    "data_output = data_dict['cc']\n",
    "del data_dict['cc']\n",
    "\n",
    "for key in data_dict.keys():\n",
    "    print(data_dict[key].shape)\n",
    "    assert data_dict[key].shape == data_dict[key].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7871dc0d-cfec-4a0c-a7e9-3f4c1cfcdbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add rh\n",
    "T0 = 273.15\n",
    "r = 0.00263*data_dict['pa']*data_dict['q']*np.exp((17.67*(data_dict['t']-T0))/(data_dict['t']-29.65))**(-1)\n",
    "data_dict['rh'] = r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0eb7d-c867-45be-8ce2-a57b2168d027",
   "metadata": {},
   "source": [
    "**Reshaping and keeping only the relevant features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b422d-a70c-4641-a76d-3f38a157a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_era = ['rh', 't', 'clwc', 'ciwc']\n",
    "feat_dya = ['rh', 'ta', 'clw', 'cli']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcb94e9-6b9d-49e5-b79c-d8501cad9dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update loc\n",
    "loc_era = {}\n",
    "for i in range(len(feat_era)):\n",
    "    loc_era[feat_era[i]] = i\n",
    "    \n",
    "# Update loc\n",
    "loc_dya = {}\n",
    "for i in range(len(feat_dya)):\n",
    "    loc_dya[feat_dya[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab773eb-e255-4cb5-814b-da7633367248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only the relevant features\n",
    "for key in feat_era:\n",
    "    data_dict[key] = np.reshape(data_dict[key], -1)\n",
    "    \n",
    "data_output = np.reshape(data_output, -1)\n",
    "\n",
    "del data_dict['q']\n",
    "del data_dict['pa']\n",
    "del data_dict['zg']\n",
    "\n",
    "no_features = len(data_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4bfc3d-f0ed-43d0-8171-4d0fad9b7aad",
   "metadata": {},
   "source": [
    "**Cast dict into ndarray**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a061da52-410e-4205-a8a3-e0cce07786dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_array = np.zeros((data_dict['q'].size, len(data_dict.keys())), dtype=np.float32)\n",
    "\n",
    "k = 0\n",
    "data_array_not_T = []\n",
    "for key in feat_era:\n",
    "    print(key)\n",
    "    data_array_not_T.append(data_dict[key])\n",
    "    del data_dict[key]\n",
    "    k += 1\n",
    "\n",
    "# Convert into np array and transpose\n",
    "data_array = np.transpose(np.array(data_array_not_T, dtype=np.float32))\n",
    "\n",
    "del data_array_not_T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f774c9cb-9e9a-49b0-be89-d432334f7043",
   "metadata": {},
   "source": [
    "**Pick the subset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eaf2b5-9052-4175-891d-fb936e7d1ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.seed(SEED)\n",
    "subset = np.random.randint(0, HFIELDS, number_horizontal_locations)\n",
    "# Convert to regular int to make check_sum JSON serializable\n",
    "check_sum = int(np.sum(subset))\n",
    "\n",
    "# Collecting all grid cell indices for the horizontal fields given by subset\n",
    "Z = np.zeros((TIMESTEPS, 27, HFIELDS), dtype=int)\n",
    "for k in range(HFIELDS):\n",
    "    Z[:,:,k] = k\n",
    "Z_res = np.reshape(Z, -1)\n",
    "subset_inds = np.concatenate([np.where(Z_res == s)[0] for s in subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04f57384-e226-4f20-bd5a-28808bba5ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = data_array[subset_inds[:num_hours*27]] #num_hours*27\n",
    "train_output = data_output[subset_inds[:num_hours*27]] #num_hours*27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e757312f-8d75-431c-a75b-320b0e0de36a",
   "metadata": {},
   "source": [
    "**Already remove the regime with clw + cli = 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "412bbcac-ee64-4eb0-b299-2e3bf1ea3664",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_0 = np.where(data_array[:, loc_era['clwc']] + data_array[:, loc_era['ciwc']] <= 1e-20)[0]\n",
    "reg_not_0 = np.where(data_array[:, loc_era['clwc']] + data_array[:, loc_era['ciwc']] > 1e-20)[0]\n",
    "\n",
    "# Relevant values to compute final MSE/R2-scores\n",
    "mse_reg_0 = np.mean(data_output[reg_0]**2)\n",
    "len_reg_0 = len(reg_0)\n",
    "len_reg_not_0 = len(reg_not_0)\n",
    "len_data_output = len(data_output)\n",
    "var_data_output = np.var(data_output)\n",
    "\n",
    "data_array = data_array[reg_not_0].copy()\n",
    "data_output = data_output[reg_not_0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d2dca90-a0b7-4589-aaad-d7835dfdaf6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1247884e-05\n",
      "(19717305, 4)\n",
      "(19717305,)\n"
     ]
    }
   ],
   "source": [
    "print(mse_reg_0)\n",
    "print(data_array.shape)\n",
    "print(data_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2316cd24-5252-4e3f-9b02-5aaf464208e9",
   "metadata": {},
   "source": [
    "**Normalize the features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28ca819d-2840-4b61-9f34-475e7c551f1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_possible_features = ['hus', 'clw', 'cli', 'ta', 'pa', 'zg', 'fr_land', 'U', 'rh', 'ps', 'hus_z', 'hus_zz', 'clw_z', 'clw_zz', 'cli_z',\\\n",
    "            'cli_zz', 'ta_z', 'ta_zz', 'pa_z', 'pa_zz', 'U_z', 'U_zz', 'rh_z', 'rh_zz']\n",
    "loc_all = {}\n",
    "for i in range(len(all_possible_features)):\n",
    "    loc_all[all_possible_features[i]] = i\n",
    "\n",
    "# Scale the data\n",
    "mean_all = [4.12205844e-03,2.25493498e-05,3.38180032e-06,2.57065512e+02,6.00030443e+04,5.64080139e+03,2.35046400e-01,1.32776682e+01,6.02512234e-01,9.86270417e+04,-1.27545273e-06,-4.02484958e-10,1.65204582e-08,-4.34660202e-11,4.29441131e-10,-1.82817316e-12,-4.68742483e-03,-7.54899040e-07,-7.51544542e+00,-1.06989723e-04,1.65615172e-03,-9.27604679e-06,-4.76200071e-05,-1.32246548e-07]\n",
    "std_all = [5.07648249e-03,5.69702638e-05,1.01308124e-05,3.00533874e+01,3.12514292e+04,5.66963918e+03,4.11184302e-01,1.11389888e+01,3.32494615e-01,6.24039256e+03,2.03179260e-06,1.17041141e-08,1.33311867e-07,1.42840744e-09,6.73384546e-09,5.07424672e-11,5.82875686e-03,6.34826092e-05,3.53136052e+00,1.13215264e-02,6.62892130e-03,6.08144307e-05,2.58065098e-04,2.49552692e-06]\n",
    "\n",
    "mean = np.concatenate([np.expand_dims(mean_all[loc_all[sel_var]], axis=0) for sel_var in feat_dya], axis = 0)\n",
    "std = np.concatenate([np.expand_dims(std_all[loc_all[sel_var]], axis=0) for sel_var in feat_dya], axis = 0)\n",
    "\n",
    "mean = np.float32(mean)\n",
    "std = np.float32(std)\n",
    "\n",
    "# Work with scaled training folds\n",
    "data_scaled = (data_array - mean)/std\n",
    "train_input = (train_input - mean)/std\n",
    "\n",
    "del data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e85bd645-28f5-4de8-b18c-a5b1ee949454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Files: polynomial_fit_cl_area_with_derivatives_degree_<deg>_dt_basis_False_no_of_regimes_<no_reg>_regime_<reg>.json\n",
    "path = '/home/b/b309170/workspace_icon-ml/symbolic_regression/baselines/polynomial_results_v2/dyamond_data/normalized_data/data_driven_regimes/'\n",
    "    \n",
    "def polynomial_predictions(n_var,input_data,output_data,coefs):\n",
    "    assert len(coefs) == n_var + 1\n",
    "    \n",
    "    ind = 0\n",
    "    out_pred = coefs[ind]\n",
    "    with open(path + 'polynomial_fit_cl_area_with_derivatives_degree_3_dt_basis_False_no_of_regimes_2_regime_1.json', 'r') as file:\n",
    "        file_content = json.load(file)\n",
    "    for key in file_content['Number of variables %d'%n_var].keys():\n",
    "        if not ('Bias' in key or 'R2' in key or 'MSE' in key):\n",
    "            # Split the square and cube into factors separated by a white space\n",
    "            key_mod = key\n",
    "            if '^2' in key:\n",
    "                key_mod = key.split('^2')[0] + ' ' + key.split('^2')[0].split(' ')[-1] + key.split('^2')[1]\n",
    "            if '^3' in key:\n",
    "                key_mod = key.split('^3')[0] + ' ' + key.split('^3')[0].split(' ')[-1] + ' ' + key.split('^3')[0].split(' ')[-1] + key.split('^3')[1]\n",
    "\n",
    "            # Multiply input features for keys such as 'cli ps'\n",
    "            prod = 1\n",
    "            for v in key_mod.split(' '):\n",
    "                prod *= input_data[:, loc_dya[v]]\n",
    "\n",
    "            # Add coefficient times feature value to the prediction\n",
    "            ind += 1\n",
    "            out_pred += coefs[ind]*prod\n",
    "            \n",
    "    out_pred = np.maximum(np.minimum(out_pred, 100), 0)\n",
    "    \n",
    "    return out_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bc8ce8d-eb6b-451b-8515-619a98605099",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 80.503913\n",
      "         Iterations: 26\n",
      "         Function evaluations: 144\n",
      "         Gradient evaluations: 36\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 35.186235\n",
      "         Iterations: 29\n",
      "         Function evaluations: 165\n",
      "         Gradient evaluations: 33\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 31.057822\n",
      "         Iterations: 45\n",
      "         Function evaluations: 294\n",
      "         Gradient evaluations: 49\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 21.454107\n",
      "         Iterations: 39\n",
      "         Function evaluations: 385\n",
      "         Gradient evaluations: 55\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 20.852094\n",
      "         Iterations: 60\n",
      "         Function evaluations: 600\n",
      "         Gradient evaluations: 75\n"
     ]
    }
   ],
   "source": [
    "def objective_polynomials(coefs, X,Y,n_var):\n",
    "    '''\n",
    "        The objective function.\n",
    "    '''\n",
    "    out_preds = np.minimum(np.maximum(polynomial_predictions(n_var, X,Y,coefs), 0), 100)\n",
    "    mse = np.mean((out_preds - Y)**2, dtype=np.float64)\n",
    "    return mse\n",
    "\n",
    "# Initialize coefficients\n",
    "coefs = {}\n",
    "with open(path + 'polynomial_fit_cl_area_with_derivatives_degree_3_dt_basis_False_no_of_regimes_2_regime_1.json', 'r') as file:\n",
    "    file_content = json.load(file)\n",
    "    for n_var in [2,3,4,5,6]:\n",
    "        coefs[n_var] = []\n",
    "        coefs[n_var].append(file_content['Number of variables %d'%n_var]['Bias'])\n",
    "        for key in file_content['Number of variables %d'%n_var].keys():\n",
    "            if not ('Bias' in key or 'R2' in key or 'MSE' in key):\n",
    "                coefs[n_var].append(file_content['Number of variables %d'%n_var][key])\n",
    "\n",
    "# Optimize objective\n",
    "coefs_out = {}\n",
    "mses_reg_1 = []\n",
    "for n_var in [2,3,4,5,6]:\n",
    "    res = minimize(objective_polynomials, coefs[n_var], args=(train_input, train_output, n_var), \\\n",
    "                   method='BFGS', options={'disp': True})\n",
    "    coefs_out['deg_3_n_var_%d'%n_var] = res.x\n",
    "    \n",
    "    # MSE on the entire dataset\n",
    "    if tl_bool:\n",
    "        preds = polynomial_predictions(n_var,data_scaled,data_output,res.x)\n",
    "    else:\n",
    "        preds = polynomial_predictions(n_var,data_scaled,data_output,coefs[n_var])\n",
    "    mses_reg_1.append(np.mean((preds - data_output)**2, dtype=np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c4b7c55-90b5-409a-bf4d-ca3116625297",
   "metadata": {},
   "outputs": [],
   "source": [
    "mses_total = [(mse_reg_0*len_reg_0 + mse_reg_1*len_reg_not_0)/len_data_output for mse_reg_1 in mses_reg_1]\n",
    "\n",
    "results = {}\n",
    "for n in range(2, 7):\n",
    "    parent_key = 'deg_3_n_feat_%d_tl_%d_num_hours_%d_seed_%d'%(n,subset_exp,num_hours,SEED)\n",
    "    results[parent_key] = {}\n",
    "    results[parent_key]['MSE'] = mses_total[n-2]\n",
    "    results[parent_key]['R2'] = 1 - mses_total[n-2]/var_data_output\n",
    "    results[parent_key]['Coefs'] = list(coefs_out['deg_3_n_var_%d'%n_var])\n",
    "    results[parent_key]['Check sum'] = check_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2547f4c-3167-4129-a4f7-061e1a1e3046",
   "metadata": {},
   "source": [
    "**Save results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71646cc2-c651-431c-9a5c-e1550d9f593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump results\n",
    "append_dict_to_json(results, '/home/b/b309170/workspace_icon-ml/symbolic_regression/evaluate_schemes/on_era5/results/era5_1979-2021/sel_polyn_deg_3_BFGS.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec83520-9ba3-4d43-8c15-5aa196ffc9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (based on the module python3/2022.01)",
   "language": "python",
   "name": "python3_2022_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

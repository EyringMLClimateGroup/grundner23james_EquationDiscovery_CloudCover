{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f72e7804-7edc-4130-aa10-b2a5b4e5ba6e",
   "metadata": {},
   "source": [
    "Executed through ~scripts/run_era5_evalute_and_transfer_learn_3.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae7838b-c3ee-46f2-9a01-217d483dbe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import sympy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "subset_exp = int(sys.argv[1])\n",
    "# subset_exp = 2\n",
    "number_horizontal_locations = 10**subset_exp\n",
    "tl_bool = True\n",
    "\n",
    "sys.path.insert(0, '~/workspace_icon-ml/cloud_cover_parameterization/')\n",
    "import my_classes\n",
    "from my_classes import load_data\n",
    "\n",
    "sys.path.insert(0, '~/workspace_icon-ml/symbolic_regression/')\n",
    "from functions import add_derivatives\n",
    "from functions import append_dict_to_json\n",
    "\n",
    "SEED = int(sys.argv[2])\n",
    "\n",
    "num_cells = int(sys.argv[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f454881a-f4c8-4db7-8f38-dee94accfbab",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c6320b-e34b-4b8c-9031-12ffa5d7c887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q\n",
      "clwc\n",
      "ciwc\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "order_of_vars = ['q', 'clwc', 'ciwc', 't', 'pa', 'zg', 'cc']\n",
    "data_dict = load_data(source='era5', days='all', order_of_vars=order_of_vars)\n",
    "\n",
    "TIMESTEPS, VLAYERS, HFIELDS = data_dict['q'].shape\n",
    "\n",
    "# Removing four upper-most levels\n",
    "for key in data_dict.keys():\n",
    "    data_dict[key] = data_dict[key][:, 4:].copy()\n",
    "\n",
    "# Data output\n",
    "data_output = data_dict['cc']\n",
    "del data_dict['cc']\n",
    "\n",
    "for key in data_dict.keys():\n",
    "    print(data_dict[key].shape)\n",
    "    assert data_dict[key].shape == data_dict[key].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1a97cb-ca8b-4cf1-ac64-5dd4a49d6a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "# Add rh\n",
    "T0 = 273.15\n",
    "r = 0.00263*data_dict['pa']*data_dict['q']*np.exp((17.67*(data_dict['t']-T0))/(data_dict['t']-29.65))**(-1)\n",
    "data_dict['rh'] = r\n",
    "\n",
    "# Add rh_z\n",
    "folder = 'rh_z'\n",
    "\n",
    "# Initialize all_npy_files with empty tensor\n",
    "all_npy_files = np.zeros((0, VLAYERS-4, HFIELDS))\n",
    "\n",
    "# Load all filenames in the folder containing the derivatives. The filenames are sorted chronologically.\n",
    "npy_file_names = sorted(os.listdir(os.path.join('~/bd1179_work/ERA5/hvcg_data', folder)))        \n",
    "\n",
    "for file in npy_file_names:\n",
    "    # Load three-hourly data and convert directly to float32\n",
    "    npy_file = np.load('~/bd1179_work/ERA5/hvcg_data/%s/%s'%(folder,file), mmap_mode='r')\n",
    "    npy_file = np.float32(npy_file[0::3].copy())\n",
    "    all_npy_files = np.concatenate((all_npy_files, npy_file), axis=0)\n",
    "data_dict[folder] = all_npy_files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae7f585-0a81-4a97-89b9-eb3b48eff176",
   "metadata": {},
   "source": [
    "**Reshaping and keeping only the relevant features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02554fbd-a45a-48a8-a130-e9dae58174c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only the relevant features\n",
    "features = ['rh', 't', 'clwc', 'ciwc', 'rh_z']\n",
    "for key in features:\n",
    "    data_dict[key] = np.reshape(data_dict[key], -1)\n",
    "    \n",
    "data_output = np.reshape(data_output, -1)\n",
    "\n",
    "del data_dict['q']\n",
    "del data_dict['pa']\n",
    "del data_dict['zg']\n",
    "\n",
    "no_features = len(data_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a85c4cd-eb04-42e6-b93f-8e9d5e56eb2e",
   "metadata": {},
   "source": [
    "**Cast dict into ndarray**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0dbaf8-d1de-4334-9035-0a6b6e4c94f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_array = np.zeros((data_dict['q'].size, len(data_dict.keys())), dtype=np.float32)\n",
    "\n",
    "k = 0\n",
    "data_array_not_T = []\n",
    "for key in features:\n",
    "    print(key)\n",
    "    data_array_not_T.append(np.reshape(data_dict[key], -1))\n",
    "    del data_dict[key]\n",
    "    k += 1\n",
    "\n",
    "# Convert into np array and transpose\n",
    "data_array = np.transpose(np.array(data_array_not_T, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8caec0-e181-4e8a-bc20-b31b952fb185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update loc\n",
    "loc = {}\n",
    "for i in range(len(features)):\n",
    "    loc[features[i]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674fcce6-2a0e-4ed6-95a4-dca59ff6d50a",
   "metadata": {},
   "source": [
    "**Pick the subset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771ad081-e735-4f7d-8490-b0e7b9645d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.seed(SEED)\n",
    "subset = np.random.randint(0, HFIELDS, number_horizontal_locations)\n",
    "# Convert to regular int to make check_sum JSON serializable\n",
    "check_sum = int(np.sum(subset))\n",
    "\n",
    "# Collecting all grid cell indices for the horizontal fields given by subset\n",
    "Z = np.zeros((TIMESTEPS, 27, HFIELDS), dtype=int)\n",
    "for k in range(HFIELDS):\n",
    "    Z[:,:,k] = k\n",
    "Z_res = np.reshape(Z, -1)\n",
    "subset_inds = np.concatenate([np.where(Z_res == s)[0] for s in subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a124893-d9d3-4477-b09d-4861fcc8f842",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = data_array[subset_inds[:num_cells]] #num_hours*27\n",
    "train_output = data_output[subset_inds[:num_cells]] #num_hours*27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee8eb97-f12a-41f8-8991-815e9b590cba",
   "metadata": {},
   "source": [
    "**Already remove the regime with clw + cli = 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8be395-eefa-4c0a-aabb-3780d19ec06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_0 = np.where(data_array[:, loc['clwc']] + data_array[:, loc['ciwc']] <= 1e-20)[0]\n",
    "reg_not_0 = np.where(data_array[:, loc['clwc']] + data_array[:, loc['ciwc']] > 1e-20)[0]\n",
    "\n",
    "# Relevant values to compute final MSE/R2-scores\n",
    "mse_reg_0 = np.mean(data_output[reg_0]**2)\n",
    "len_reg_0 = len(reg_0)\n",
    "len_reg_not_0 = len(reg_not_0)\n",
    "len_data_output = len(data_output)\n",
    "var_data_output = np.var(data_output)\n",
    "\n",
    "data_array = data_array[reg_not_0]\n",
    "data_output = data_output[reg_not_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0455a9-5010-44e9-abd6-35151b7a10a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mse_reg_0)\n",
    "print(data_array.shape)\n",
    "print(data_output.shape)\n",
    "\n",
    "# Should be 338023\n",
    "len_reg_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f9dda-8c13-47a6-ad1e-caf0b9924257",
   "metadata": {},
   "source": [
    "**Normalize the features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43603af8-79bb-4ffb-a859-987be37681b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_possible_features = ['hus', 'clw', 'cli', 'ta', 'pa', 'zg', 'fr_land', 'U', 'rh', 'ps', 'hus_z', 'hus_zz', 'clw_z', 'clw_zz', 'cli_z',\\\n",
    "            'cli_zz', 'ta_z', 'ta_zz', 'pa_z', 'pa_zz', 'U_z', 'U_zz', 'rh_z', 'rh_zz']\n",
    "loc = {}\n",
    "for i in range(len(all_possible_features)):\n",
    "    loc[all_possible_features[i]] = i\n",
    "features = ['rh', 'ta', 'clw', 'cli', 'rh_z']\n",
    "\n",
    "# Scale the data\n",
    "mean_all = [4.12205844e-03,2.25493498e-05,3.38180032e-06,2.57065512e+02,6.00030443e+04,5.64080139e+03,2.35046400e-01,1.32776682e+01,6.02512234e-01,9.86270417e+04,-1.27545273e-06,-4.02484958e-10,1.65204582e-08,-4.34660202e-11,4.29441131e-10,-1.82817316e-12,-4.68742483e-03,-7.54899040e-07,-7.51544542e+00,-1.06989723e-04,1.65615172e-03,-9.27604679e-06,-4.76200071e-05,-1.32246548e-07]\n",
    "std_all = [5.07648249e-03,5.69702638e-05,1.01308124e-05,3.00533874e+01,3.12514292e+04,5.66963918e+03,4.11184302e-01,1.11389888e+01,3.32494615e-01,6.24039256e+03,2.03179260e-06,1.17041141e-08,1.33311867e-07,1.42840744e-09,6.73384546e-09,5.07424672e-11,5.82875686e-03,6.34826092e-05,3.53136052e+00,1.13215264e-02,6.62892130e-03,6.08144307e-05,2.58065098e-04,2.49552692e-06]\n",
    "\n",
    "mean = np.concatenate([np.expand_dims(mean_all[loc[sel_var]], axis=0) for sel_var in features], axis = 0)\n",
    "std = np.concatenate([np.expand_dims(std_all[loc[sel_var]], axis=0) for sel_var in features], axis = 0)\n",
    "\n",
    "# Work with scaled training folds\n",
    "data_scaled = (data_array - mean)/std\n",
    "train_input = (train_input - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51702441-2dbb-4e54-ab31-796a587b2fb7",
   "metadata": {},
   "source": [
    "Optimize coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e734a3-580a-48e4-b2c4-a891a42b5685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See ~/symbolic_regression/finding_symmetries/pysr_results_dyamond_on_regimes/optimize_coefs_EQ4.ipynb\n",
    "def func(X, a,b,c,d,e,f,g,h,i,j):\n",
    "    x0 = X[:, 0] \n",
    "    x1 = X[:, 1] \n",
    "    x2 = X[:, 2] \n",
    "    x3 = X[:, 3]\n",
    "    x4 = X[:, 4]\n",
    "    \n",
    "    # Modified to always satisfy RH-constraint\n",
    "    x0 = np.maximum(x0, 1/(2*c*d)*(-c*x1**2-a))\n",
    "    \n",
    "    return a*x0 - b*x1 + c*x0*(d*x0 + x1**2) + x4**2*(e*x4 + f) + g - h/(x2 + i*x3 + j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1685e5-d5ee-4ea7-b4e5-af0566792377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sci\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1fdcef-6f16-45f7-a22c-17e90674665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(P, X,Y):\n",
    "    '''\n",
    "        The objective function.\n",
    "    '''\n",
    "    a,b,c,d,e,f,g,h,i,j = P\n",
    "    train_preds = np.minimum(np.maximum(func(X, a,b,c,d,e,f,g,h,i,j), 0), 100)\n",
    "    train_mse = np.mean((train_preds - Y)**2, dtype=np.float64)\n",
    "\n",
    "    return train_mse\n",
    "\n",
    "(a,b,c,d,e,f,g,h,i,j) = (38.6562122, 43.53500518, 19.78403208, 1.13637902, 0.35299939,\\\n",
    "                         4.04888686, 44.21730274, 2.03128527, 0.66971589, 0.6409019)\n",
    "\n",
    "if tl_bool:\n",
    "    res = minimize(objective, (a,b,c,d,e,f,g,h,i,j), args=(train_input, train_output), \\\n",
    "                   method='Nelder-Mead', options={'disp': True})\n",
    "else:\n",
    "    # Compute the MSE and terminate if not tl_bool\n",
    "    P = (a,b,c,d,e,f,g,h,i,j)\n",
    "    mse_reg_1 = objective(P, data_scaled, data_output)\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    mse_new_total = (mse_reg_0*len_reg_0 + mse_reg_1*len_reg_not_0)/len_data_output\n",
    "    r2_new_total = 1 - mse_new_total/var_data_output\n",
    "\n",
    "    print(mse_new_total, r2_new_total)\n",
    "\n",
    "    parent_key = 'pysr_EQ4_no_tl'\n",
    "    results[parent_key] = {}\n",
    "    results[parent_key]['MSE'] = mse_new_total\n",
    "    results[parent_key]['R2'] = r2_new_total\n",
    "    results[parent_key]['Coefficients'] = list(res.x)\n",
    "    # Should be the same for all runs\n",
    "    results[parent_key]['Check_sum'] = check_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "373a1caf-7c49-4937-8e50-11f244f3a26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.63862663,  1.01550394,  0.98765924, 32.27990715, 28.52998015,\n",
       "        1.23986714, 21.48996266, 56.16978356,  2.89101861])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d427145e-6f05-4f04-9a73-8559d22f28e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.64, 1.02, 0.99, 32.28, 28.53, 1.24, 21.49, 56.17, 2.89]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.round(res.x, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30ae5e9-d72c-4cfa-b4e9-1e3f4916ba7e",
   "metadata": {},
   "source": [
    "New values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76d5385f-9ef3-4996-b0d9-3557b9c08525",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_reg_1 = objective(res.x, data_scaled, data_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f50f27f-a8ad-4998-b38d-d6814f8621bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369.61885130344353 -0.13658246476481972\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "mse_new_total = (mse_reg_0*len_reg_0 + mse_reg_1*len_reg_not_0)/len_data_output\n",
    "r2_new_total = 1 - mse_new_total/var_data_output\n",
    "\n",
    "print(mse_new_total, r2_new_total)\n",
    "\n",
    "parent_key = 'pysr_EQ4_mod_tl_%d_num_cells_%d_seed_%d'%(subset_exp,num_cells,SEED)\n",
    "results[parent_key] = {}\n",
    "results[parent_key]['MSE'] = mse_new_total\n",
    "results[parent_key]['R2'] = r2_new_total\n",
    "results[parent_key]['Coefficients'] = list(res.x)\n",
    "# Should be the same for all runs\n",
    "results[parent_key]['Check_sum'] = check_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016d71c9-c056-49a4-95e4-e67be9fddadb",
   "metadata": {},
   "source": [
    "**Save results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5128a4ef-6097-485d-9a13-cccf601a5cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump results\n",
    "append_dict_to_json(results, '~/workspace_icon-ml/symbolic_regression/evaluate_schemes/on_era5/results/era5_1979-2021/era5_tuned_pysr_EQ4_mod.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72f416da-ea29-4e6f-bb67-7b74e2065b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(P,X):\n",
    "#     '''\n",
    "#         The objective function.\n",
    "#     '''\n",
    "#     a,b,c,d,e,f,g,h,i,j = P\n",
    "#     preds = [np.minimum(np.maximum(func(X[k_ind], a,b,c,d,e,f,g,h,i,j), 0), 100) for k_ind in range(X.shape[0])]\n",
    "\n",
    "#     return preds\n",
    "\n",
    "# predict(res.x, data_scaled)\n",
    "\n",
    "# plt.hist(data_output,bins=100, histtype='step', color='k')\n",
    "# plt.hist(predict(res.x, data_scaled),bins=100, histtype='step')\n",
    "\n",
    "# plt.yscale('log')\n",
    "# plt.legend(['ERA5', 'Eq. 4'])\n",
    "# plt.savefig('~/workspace_icon-ml/symbolic_regression/evaluate_schemes/on_era5/results/era5_1979-2021/era5_tuned_pysr_EQ4_mod.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff82552-ab84-425a-a025-2402ca07f9ef",
   "metadata": {},
   "source": [
    "Original values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fd1d91c-237d-4650-b52a-1cd1c70184b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mse_reg_1 = objective((a,b,c,d,e,f,g,h,i,j), data_scaled, data_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0d5758c-2eb2-4ab2-9d5e-d385dbb7089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse_orig_total = (mse_reg_0*len_reg_0 + mse_reg_1*len_reg_not_0)/len_data_output\n",
    "# r2_orig_total = 1 - mse_orig_total/var_data_output\n",
    "\n",
    "# print(mse_orig_total, r2_orig_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c69bee5-c9a1-46f4-9394-511169cc319a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clouds",
   "language": "python",
   "name": "clouds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I want to diagnose a cloud in the DYAMOND output whenever \n",
    "\n",
    "qi +  qc > 1e-6\n",
    "\n",
    "Code is okay so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs 480GB\n",
    "import os\n",
    "import gc\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nwp_R2B10_lkm1007_atm_3d_tot_qc_dia_ml_20160831T000000Z.nc\n"
     ]
    }
   ],
   "source": [
    "# Define all paths\n",
    "path = '~/bd1179_work/DYAMOND'\n",
    "path_clc = '~/bd1179_work/DYAMOND/clc_data'\n",
    "path_content = os.listdir(path)\n",
    "\n",
    "threshold = 1e-6\n",
    "\n",
    "# Iterate over qc files. Do not process coarse-grained qc and qi files.\n",
    "files = [path_content[k] for k in range(len(path_content)) if 'tot_qc_dia' in path_content[k] and 'Z.nc' in path_content[k]]\n",
    "\n",
    "# Which file to load\n",
    "for file in files:\n",
    "    print(file)\n",
    "    # Do not overwrite\n",
    "    if not (True in [file.split('_')[-1] in os.listdir(path_clc)[k] for k in range(len(os.listdir(path_clc)))]):\n",
    "        # Load qc file\n",
    "        input_file_qc = os.path.join(path, file)\n",
    "        ds_qc = xr.open_dataset(input_file_qc)\n",
    "\n",
    "        # Load qi file\n",
    "        input_file_qi = input_file_qc.replace('tot_qc_dia', 'tot_qi_dia')\n",
    "        ds_qi = xr.open_dataset(input_file_qi)\n",
    "\n",
    "        # Extract coordinates\n",
    "        time_coo = ds_qi.time\n",
    "        height_coo = ds_qi.height\n",
    "\n",
    "        # Up to a height of 21km: 322 Gigabytes are required to hold both ds_qc and ds_qi\n",
    "        ds_qc = getattr(ds_qc, 'param212.1.0').values[:, -60:]\n",
    "        ds_qi = getattr(ds_qi, 'param213.1.0').values[:, -60:]\n",
    "\n",
    "        (TIME, VERT, HOR) = ds_qc.shape\n",
    "\n",
    "        # Skip problematic files for now\n",
    "        if ds_qi.shape != (TIME, VERT, HOR):\n",
    "            print('ds_qc shape: %s'%str((TIME, VERT, HOR)))\n",
    "            print('ds_qi shape: %s'%str(ds_qi.shape))\n",
    "            continue\n",
    "\n",
    "        # Initialize byte ndarray\n",
    "        clc_out = np.ones(ds_qc.shape, dtype=np.bool_)\n",
    "\n",
    "        # Loop over temporal dimension so that ds_qc + ds_qi doesn't have to be computed at once (otherwise we run into another OOM error)\n",
    "        for t in range(TIME):\n",
    "            clc_out[t] = (ds_qc[t] + ds_qi[t] > threshold)\n",
    "\n",
    "        # Clean memory\n",
    "        del ds_qc, ds_qi\n",
    "        gc.collect()\n",
    "\n",
    "        clc_new_da = xr.DataArray(np.int8(clc_out), coords={'time':time_coo, 'height':height_coo[-60:]}, \n",
    "                              dims=['time', 'height', 'cells'], name='clc')\n",
    "\n",
    "        # Save it in a new file\n",
    "        output_file = input_file_qi.replace('tot_qi_dia', 'clc')\n",
    "        clc_new_da.to_netcdf(output_file)\n",
    "\n",
    "        # Remove original qi and qc files\n",
    "        os.remove(input_file_qc)\n",
    "        os.remove(input_file_qi)\n",
    "\n",
    "        # Clean memory\n",
    "        del clc_new_da, clc_out\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING\n",
    "As a first test I compared the means, max/means with the linearly interpolated data to see if they are close. <br>\n",
    "As a second test I compare the vertically interpolated cloud cover for an arbitrary data point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_file = xr.open_dataset('clc_dei4_NARVALI_2013122600_cloud_DOM01_ML_0023.nc')\n",
    "# output_file = xr.open_dataset('int_var_clc_dei4_NARVALI_2013122600_cloud_DOM01_ML_0023.nc')\n",
    "\n",
    "# input_clc = input_file.clc.values\n",
    "# output_clc = output_file.clc.values\n",
    "\n",
    "# input_clc_mean = np.mean(input_clc[0], axis=1)\n",
    "# output_clc_mean = np.mean(output_clc[0], axis=1)\n",
    "\n",
    "# input_clc_max = np.max(input_clc[0], axis=1)\n",
    "# output_clc_max = np.max(output_clc[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(11,3))\n",
    "\n",
    "# ax_1 = fig.add_subplot(121)\n",
    "# ax_1.plot(input_clc_mean, np.arange(len(input_clc_mean)))\n",
    "\n",
    "# ax_2 = fig.add_subplot(122)\n",
    "# ax_2.plot(output_clc_mean, np.arange(len(output_clc_mean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(11,3))\n",
    "\n",
    "# ax_1 = fig.add_subplot(121)\n",
    "# ax_1.plot(input_clc_max, np.arange(len(input_clc_max)))\n",
    "\n",
    "# ax_2 = fig.add_subplot(122)\n",
    "# ax_2.plot(output_clc_max, np.arange(len(output_clc_max)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# m = 3000000\n",
    "\n",
    "# fig = plt.figure(figsize=(11,3))\n",
    "\n",
    "# ax_1 = fig.add_subplot(121)\n",
    "# ax_1.plot(input_clc[0][:, m], np.arange(len(input_clc_max)))\n",
    "\n",
    "# ax_2 = fig.add_subplot(122)\n",
    "# ax_2.plot(output_clc[0][:, m], np.arange(len(output_clc_max)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Arbitrary data point\n",
    "# k = 20\n",
    "# l = 2071456\n",
    "\n",
    "# z_u = zh_lr[k, l] #3647.9666\n",
    "# z_l = zh_lr[k+1, l] #3069.0796\n",
    "# np.where(zh_hr[:, l] <= z_u) #51 and above\n",
    "# np.where(zh_hr[:, l] >= z_l) #52 and below\n",
    "# # clc[0, 50, l] #83.6644\n",
    "# # clc[0, 51, l] #78.92006\n",
    "# # clc[0, 52, l] #74.58538"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clc_out[0,k,l] == np.max([clc[0, 50, l], clc[0, 51, l], clc[0, 52, l]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (based on the module python3/2022.01)",
   "language": "python",
   "name": "python3_2022_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

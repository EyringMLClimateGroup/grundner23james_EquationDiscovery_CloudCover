{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sundqvist Scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about we fit the Sundqvist model where we fit the tuning parameters to the data? <br>\n",
    "We let the parameters depend on whether they are taken over land or over the sea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All samples (190119664): 5.5s per entry of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, '/home/b/b309170/workspace_icon-ml/symbolic_regression/')\n",
    "from functions import evaluate_sundqvist\n",
    "\n",
    "output_var = sys.argv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load columns of data\n",
    "folder_data = '/home/b/b309170/my_work/icon-ml_data/cloud_cover_parameterization/neighborhood_based_SR_DYAMOND/'\n",
    "\n",
    "input_data = np.load(os.path.join(folder_data, 'cloud_cover_input_dyamond.npy'))\n",
    "if output_var == 'cl_volume':\n",
    "    output_data = np.load(os.path.join(folder_data, 'cloud_cover_output_dyamond.npy'))\n",
    "elif output_var == 'cl_area':\n",
    "    output_data = np.load(os.path.join(folder_data, 'cloud_area_output_dyamond.npy'))\n",
    "\n",
    "new_features = ['hus', 'clw', 'cli', 'ta', 'pa', 'zg', 'fr_land', 'U', 'rh', 'ps', 'hus_z', 'hus_zz', 'clw_z', 'clw_zz', 'cli_z',\\\n",
    "                'cli_zz', 'ta_z', 'ta_zz', 'pa_z', 'pa_zz', 'U_z', 'U_zz', 'rh_z', 'rh_zz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_total, no_of_features = input_data.shape\n",
    "\n",
    "# Split into train/valid\n",
    "training_folds = []\n",
    "validation_folds = []\n",
    "two_week_incr = samples_total//6\n",
    "\n",
    "for i in range(3):\n",
    "    # Note that this is a temporal split since time was the first dimension in the original tensor\n",
    "    first_incr = np.arange(samples_total//6*i, samples_total//6*(i+1))\n",
    "    second_incr = np.arange(samples_total//6*(i+3), samples_total//6*(i+4))\n",
    "\n",
    "    validation_folds.append(np.append(first_incr, second_incr))\n",
    "    training_folds.append(np.arange(samples_total))\n",
    "    training_folds[i] = np.delete(training_folds[i], validation_folds[i])\n",
    "\n",
    "# The second fold yields the best model\n",
    "input_train = input_data[training_folds[1]]\n",
    "input_valid = input_data[validation_folds[1]]\n",
    "output_train = output_data[training_folds[1]]\n",
    "output_valid = output_data[validation_folds[1]]\n",
    "\n",
    "# Remove input_data, output_data\n",
    "del input_data, output_data, training_folds, validation_folds\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(190119664, 24)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To locate variables\n",
    "loc = {}\n",
    "for i in range(len(new_features)):\n",
    "    loc[new_features[i]] = i\n",
    "    \n",
    "input_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the training data into cells over land vs sea\n",
    "land_ind = np.where(input_train[:, loc['fr_land']] > 0.5)[0]\n",
    "sea_ind = np.where(input_train[:, loc['fr_land']] <= 0.5)[0]\n",
    "\n",
    "input_land = input_train[land_ind]\n",
    "output_land = output_train[land_ind]\n",
    "input_sea = input_train[sea_ind]\n",
    "output_sea = output_train[sea_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance with the best hyperparameter setting (To run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From best_results.txt\n",
    "if output_var == 'cl_volume':\n",
    "    best_land = [0.95, 0.16, 0.5, 2.12]\n",
    "    best_sea = [0.95, 0.11, 0.9, 2.12]\n",
    "elif output_var == 'cl_area':\n",
    "    best_land = [0.9, 0.01, 0.55, 2.12]\n",
    "    best_sea = [0.95, 0.01, 0.55, 2.12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differentiate between original, manually and automatically tuned! I expect this codes needs an hour to run\n",
    "mse_train = evaluate_sundqvist(input_train, output_train, loc, tuned='custom', best_land=best_land, best_sea=best_sea, compute_r2=False)\n",
    "mse_train_land = evaluate_sundqvist(input_land, output_land, loc, tuned='custom', best_land=best_land, best_sea=best_sea, compute_r2=False)\n",
    "mse_train_sea = evaluate_sundqvist(input_sea, output_sea, loc, tuned='custom', best_land=best_land, best_sea=best_sea, compute_r2=False)\n",
    "mse_valid = evaluate_sundqvist(input_valid, output_valid, loc, tuned='custom', best_land=best_land, best_sea=best_sea, compute_r2=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to JSON\n",
    "results = {}\n",
    "results['Order of parameters'] = 'rsat, r0_top, r0_surf, n'\n",
    "results['Best params land'] = str(best_land)\n",
    "results['Best params sea'] = str(best_sea)\n",
    "results['Training MSE'] = mse_train\n",
    "results['Land MSE'] = mse_train_land\n",
    "results['Sea MSE'] = mse_train_sea\n",
    "results['Validation MSE'] = mse_valid\n",
    "\n",
    "with open('/home/b/b309170/workspace_icon-ml/symbolic_regression/baselines/sundqvist_tuning_dyamond/results_grid_search_%s.json'%output_var, 'w') as file:\n",
    "    json.dump(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick test of old parameters (found on QUBICC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_train = evaluate_sundqvist(input_train, output_train, loc, tuned='manually', compute_r2=False)\n",
    "mse_train_land = evaluate_sundqvist(input_land, output_land, loc, tuned='manually', compute_r2=False)\n",
    "mse_train_sea = evaluate_sundqvist(input_sea, output_sea, loc, tuned='manually', compute_r2=False)\n",
    "mse_valid = evaluate_sundqvist(input_valid, output_valid, loc, tuned='manually', compute_r2=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1373.151097511083\n",
      "1510.730314937607\n",
      "1329.9443211258374\n",
      "1382.5448965542282\n"
     ]
    }
   ],
   "source": [
    "# It is slightly better than a constant output model...\n",
    "print(mse_train)\n",
    "print(mse_train_land)\n",
    "print(mse_train_sea)\n",
    "print(mse_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clouds",
   "language": "python",
   "name": "clouds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56e4d405-d113-4c27-965b-bb01807ad169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "\n",
    "sys.path.insert(0, '~/workspace_icon-ml/symbolic_regression')\n",
    "from functions import append_dict_to_json\n",
    "from sklearn import tree\n",
    "\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd38bf0e-4407-4709-a661-41216c023ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_regimes = 2\n",
    "regime = 1\n",
    "\n",
    "# no_of_regimes = int(sys.argv[1])\n",
    "# regime = int(sys.argv[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12a0882d-f1b9-443a-b500-d8d10f0d8cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be used to quickly compute the mse on all regimes!\n",
    "def mse_all_regimes(M):\n",
    "    '''\n",
    "        M: Contains [mse_reg_1, mse_reg_2, ...] depending on no_regimes\n",
    "        Computes the validation error on all regimes knowing the ones on the single regimes\n",
    "    '''\n",
    "\n",
    "    # Known parameters\n",
    "    mse_reg_0 = 0.0353\n",
    "    n_0 = 32419018\n",
    "\n",
    "    n_21 = 62640812\n",
    "\n",
    "    n_31 = 5742663\n",
    "    n_32 = 56898149\n",
    "\n",
    "    n_41 = 5742663\n",
    "    n_42 = 18367245\n",
    "    n_43 = 38530904\n",
    "\n",
    "    N = n_0 + n_21\n",
    "    \n",
    "    # Two regimes\n",
    "    if len(M) == 1:\n",
    "        return (n_0*mse_reg_0 + n_21*M[0])/N\n",
    "        \n",
    "    # Three regimes\n",
    "    if len(M) == 2:\n",
    "        return (n_0*mse_reg_0 + n_31*M[0] + n_32*M[1])/N\n",
    "        \n",
    "    # Four regimes:\n",
    "    if len(M) == 3:\n",
    "        return (n_0*mse_reg_0 + n_41*M[0] + n_42*M[1] + n_43*M[2])/N        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2f9173-f118-4d30-803c-db6b13cc05f5",
   "metadata": {},
   "source": [
    "**Read data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cb7228f-5656-4737-b862-c0072551e8bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_possible_features = ['hus', 'clw', 'cli', 'ta', 'pa', 'zg', 'fr_land', 'U', 'rh', 'ps', 'hus_z', 'hus_zz', 'clw_z', 'clw_zz', 'cli_z',\\\n",
    "            'cli_zz', 'ta_z', 'ta_zz', 'pa_z', 'pa_zz', 'U_z', 'U_zz', 'rh_z', 'rh_zz']\n",
    "\n",
    "loc_all = {}\n",
    "for i in range(len(all_possible_features)):\n",
    "    loc_all[all_possible_features[i]] = i\n",
    "    \n",
    "# For the five-feature equations only the first five features are used\n",
    "features = ['rh', 'ta', 'clw', 'cli', 'rh_z', 'rh_zz', 'pa_z', 'pa_zz']\n",
    "# elif regime_1_improving_eq_16:\n",
    "#     features = ['rh_zz', 'pa_z', 'pa_zz']\n",
    "    \n",
    "no_features = len(features)\n",
    "\n",
    "loc_sel = {}\n",
    "for i in range(len(features)):\n",
    "    loc_sel[features[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8462c5d-87c6-4d8d-983f-7daf8582855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = os.path.join('~/my_work/icon-ml_data/cloud_cover_parameterization/neighborhood_based_SR_DYAMOND')\n",
    "\n",
    "# Load the input data and pick the five best features (rh, ta, clw, cli, rh_z)\n",
    "input_data = np.load(path_data + '/cloud_cover_input_dyamond.npy')\n",
    "input_data = np.concatenate([np.expand_dims(input_data[:, loc_all[sel_var]], axis=1) for sel_var in features], axis = 1)\n",
    "\n",
    "output_data = np.load(path_data + '/cloud_area_output_dyamond.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6831a5fb-6fcb-4785-86a9-700a0fe82730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(285179494, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(samples_total, no_of_features) = input_data.shape\n",
    "(samples_total, no_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b0eaa09-11a3-485e-b9ff-6befe674d5b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct training and validation data\n",
    "training_folds = []\n",
    "validation_folds = []\n",
    "two_week_incr = samples_total//6\n",
    "\n",
    "for i in range(3):\n",
    "    # Note that this is a temporal split since time was the first dimension in the original tensor\n",
    "    first_incr = np.arange(samples_total//6*i, samples_total//6*(i+1))\n",
    "    second_incr = np.arange(samples_total//6*(i+3), samples_total//6*(i+4))\n",
    "\n",
    "    validation_folds.append(np.append(first_incr, second_incr))\n",
    "    training_folds.append(np.arange(samples_total))\n",
    "    training_folds[i] = np.delete(training_folds[i], validation_folds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff49c846-d3de-4b64-b8d5-42f1db80e37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The second fold yields the best model\n",
    "flattened_input_train = input_data[training_folds[1]]\n",
    "flattened_input_valid = input_data[validation_folds[1]]\n",
    "flattened_output_train = output_data[training_folds[1]]\n",
    "flattened_output_valid = output_data[validation_folds[1]]\n",
    "    \n",
    "# Remove input_data, output_data\n",
    "del input_data, output_data, training_folds, validation_folds\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18a94f27-da39-4411-9bf0-d139e8fc4c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if no_of_regimes > 1:\n",
    "    # Already remove the regime with clw + cli = 0\n",
    "    reg_not_0_train = np.where(flattened_input_train[:, loc_sel['clw']] + flattened_input_train[:, loc_sel['cli']] > 1e-20)[0]\n",
    "    flattened_input_train = flattened_input_train[reg_not_0_train]\n",
    "    flattened_output_train = flattened_output_train[reg_not_0_train]\n",
    "\n",
    "    reg_not_0_valid = np.where(flattened_input_valid[:, loc_sel['clw']] + flattened_input_valid[:, loc_sel['cli']] > 1e-20)[0]\n",
    "    flattened_input_valid = flattened_input_valid[reg_not_0_valid]\n",
    "    flattened_output_valid = flattened_output_valid[reg_not_0_valid]\n",
    "\n",
    "    # We only need to split the regimes further if no_of_regimes > 2\n",
    "    if no_of_regimes > 2:\n",
    "        # Take a subset of the data to train the decision tree on\n",
    "        subset_size = 10**7 # or 10**6\n",
    "\n",
    "        inds = np.random.randint(0, flattened_input_train.shape[0], subset_size)\n",
    "        input_subset = flattened_input_train[inds]\n",
    "        output_subset = flattened_output_train[inds]\n",
    "\n",
    "        classification_tree = tree.DecisionTreeRegressor(max_depth=3, max_leaf_nodes=(no_of_regimes-1)) # set max_depth to [2,3]\n",
    "        classification_tree.fit(input_subset, output_subset)\n",
    "        text_representation = tree.export_text(classification_tree, feature_names=features)\n",
    "        print(text_representation)\n",
    "\n",
    "        ind_reg_train = np.where(classification_tree.apply(flattened_input_train) == regime)\n",
    "        ind_reg_valid = np.where(classification_tree.apply(flattened_input_valid) == regime)\n",
    "\n",
    "        # Sometimes, the regime is called differently...\n",
    "        if np.sum(ind_reg_train) == 0:\n",
    "            print('The regime %d does not exist, switching to regime %d instead.'%(regime, no_of_regimes))\n",
    "            ind_reg_train = np.where(classification_tree.apply(flattened_input_train) == no_of_regimes)\n",
    "            ind_reg_valid = np.where(classification_tree.apply(flattened_input_valid) == no_of_regimes)\n",
    "\n",
    "        flattened_input_train = flattened_input_train[ind_reg_train]\n",
    "        flattened_input_valid = flattened_input_valid[ind_reg_valid]\n",
    "\n",
    "        flattened_output_train = flattened_output_train[ind_reg_train]\n",
    "        flattened_output_valid = flattened_output_valid[ind_reg_valid]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5711b1-f92c-47db-bef5-f162a9559355",
   "metadata": {},
   "source": [
    "**Normalize the features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7d119dc-7b3a-4fa0-974c-a1b755b7b40b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "mean_all = [4.12205844e-03,2.25493498e-05,3.38180032e-06,2.57065512e+02,6.00030443e+04,5.64080139e+03,2.35046400e-01,1.32776682e+01,6.02512234e-01,9.86270417e+04,-1.27545273e-06,-4.02484958e-10,1.65204582e-08,-4.34660202e-11,4.29441131e-10,-1.82817316e-12,-4.68742483e-03,-7.54899040e-07,-7.51544542e+00,-1.06989723e-04,1.65615172e-03,-9.27604679e-06,-4.76200071e-05,-1.32246548e-07]\n",
    "std_all = [5.07648249e-03,5.69702638e-05,1.01308124e-05,3.00533874e+01,3.12514292e+04,5.66963918e+03,4.11184302e-01,1.11389888e+01,3.32494615e-01,6.24039256e+03,2.03179260e-06,1.17041141e-08,1.33311867e-07,1.42840744e-09,6.73384546e-09,5.07424672e-11,5.82875686e-03,6.34826092e-05,3.53136052e+00,1.13215264e-02,6.62892130e-03,6.08144307e-05,2.58065098e-04,2.49552692e-06]\n",
    "\n",
    "mean = np.concatenate([np.expand_dims(mean_all[loc_all[sel_var]], axis=0) for sel_var in features], axis = 0)\n",
    "std = np.concatenate([np.expand_dims(std_all[loc_all[sel_var]], axis=0) for sel_var in features], axis = 0)\n",
    "\n",
    "# Work with scaled training folds\n",
    "train_data_scaled = (flattened_input_train - mean)/std\n",
    "valid_data_scaled = (flattened_input_valid - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed61768-fddd-48a7-b717-c947d730d70c",
   "metadata": {},
   "source": [
    "**Read and evaluate the equations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3097c63a-98be-4372-a78e-926bc3e2e7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_expr(expr, num_digits):\n",
    "    return expr.xreplace({n : round(n, num_digits) for n in expr.atoms(sp.Number)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "edb589b0-aa6c-4dfe-92a6-565c5b03e112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x**3\n",
    "\n",
    "def pow_abs(x, y):\n",
    "    return np.abs(x)**y\n",
    "\n",
    "def sqrt_abs(x):\n",
    "    # sqrt(abs(x))\n",
    "    return (x**2)**(1/4)\n",
    "\n",
    "def relu(x):\n",
    "    # max(0, x)\n",
    "    return (x/np.abs(x) + 1)/2*x\n",
    "\n",
    "def neg(x):\n",
    "    return (-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "194e7b5f-67b2-4aaa-ba7b-26858e36ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, x1, x2, x3, x4, x5, x6, x7 = sp.symbols('x0 x1 x2 x3 x4 x5 x6 x7')\n",
    "rh, ta, clw, cli, rh_z, rh_zz, pa_z, pa_zz = sp.symbols('rh ta clw cli rh_z rh_zz pa_z pa_zz')\n",
    "\n",
    "X0 = (rh - mean[0])/std[0]\n",
    "X1 = (ta - mean[1])/std[1]\n",
    "X2 = (clw - mean[2])/std[2]\n",
    "X3 = (cli - mean[3])/std[3]\n",
    "X4 = (rh_z - mean[4])/std[4]\n",
    "X5 = (rh_zz - mean[5])/std[5]\n",
    "X6 = (pa_z - mean[6])/std[6]\n",
    "X7 = (pa_zz - mean[7])/std[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d503a491-ffeb-46b8-9a13-9fdcd10e02d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Evaluate on a specified number of regimes and a specified regime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "988d3ba7-fdb7-4a55-b8a0-b8f77c86f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def b(x):\n",
    "    return np.minimum(np.maximum(x, 0), 100)\n",
    "    \n",
    "def process_hof_file(folder_abs_path, regime=regime, features=features, train_data_scaled=train_data_scaled, \\\n",
    "                     flattened_output_train=flattened_output_train, valid_data_scaled=valid_data_scaled, flattened_output_valid=flattened_output_valid):\n",
    "    '''\n",
    "        folder: Abs path of parent folder of the Hall of fame CSV\n",
    "                E.g.: '~/workspace_icon-ml/symbolic_regression/finding_symmetries/pysr_results_dyamond_on_regimes/no_of_regimes_2/regime_1/tmp5t8dshps'\n",
    "    '''\n",
    "    if 'hall_of_fame.csv' not in os.listdir(os.path.join(folder_abs_path)):\n",
    "        return 1\n",
    "    \n",
    "    # Read hall_of_fame.csv\n",
    "    file = os.path.join(folder_abs_path, 'hall_of_fame.csv')\n",
    "    hof = pd.read_csv(file, sep=',')\n",
    "    \n",
    "    folder = folder_abs_path.split('/')[-1]\n",
    "    \n",
    "    # Dictionary to save the results in\n",
    "    d = {}\n",
    "    d[folder] = {}\n",
    "    \n",
    "    for eq_num in range(len(hof)):\n",
    "        d[folder]['Equation %d'%eq_num] = {}\n",
    "        eq = hof.iloc[eq_num]['Equation']\n",
    "        eq_sp = sp.sympify(eq, locals={'cube': cube, 'pow_abs': pow_abs, 'sqrt_abs': sqrt_abs, 'relu': relu, 'neg': neg})\n",
    "\n",
    "        input_tuple = []\n",
    "        for k in range(len(features)):\n",
    "            input_tuple.append(globals()['x%d'%k])\n",
    "        input_tuple = tuple(input_tuple)\n",
    "        eq_lb = sp.lambdify(input_tuple, eq_sp)\n",
    "\n",
    "        ## Evaluate the equations\n",
    "        train_preds = b(eq_lb(*train_data_scaled.T))\n",
    "        valid_preds = b(eq_lb(*valid_data_scaled.T))\n",
    "\n",
    "        ## Compute MSE\n",
    "        train_mse = np.mean((train_preds - flattened_output_train)**2, dtype=np.float64)\n",
    "        valid_mse = np.mean((valid_preds - flattened_output_valid)**2, dtype=np.float64)\n",
    "\n",
    "        # Write output to json\n",
    "        d[folder]['Equation %d'%eq_num]['Equation w.r.t. normalized vars'] = str(round_expr(sp.simplify(eq), 2))\n",
    "\n",
    "        # Cannot always plug in symbols into lambdified function\n",
    "        subs_set = []\n",
    "        for k in range(len(features)):\n",
    "            subs_set.append((input_tuple[k], globals()['X%d'%k]))\n",
    "        subs_set = set(subs_set)\n",
    "        eq_sp_orig_inputs = eq_sp.subs(subs_set)\n",
    "        \n",
    "        # Troublesome rounding! It would probably have been better to use the rounding-function from \n",
    "        # symbolic_regression/finding_symmetries/pysr_results_dyamond_on_regimes/save_optimized_eqns.ipynb\n",
    "        d[folder]['Equation %d'%eq_num]['Equation w.r.t. physical vars'] = str(round_expr(sp.simplify(eq_sp_orig_inputs), 2))\n",
    "        try:\n",
    "            d[folder]['Equation %d'%eq_num]['$df/drh$'] = '%s'%round_expr(sp.simplify(eq_sp_orig_inputs.diff('rh')), 2)\n",
    "            d[folder]['Equation %d'%eq_num]['$df/dclw$'] = '%s'%round_expr(sp.simplify(eq_sp_orig_inputs.diff('clw')), 2)\n",
    "            d[folder]['Equation %d'%eq_num]['$df/dcli$'] = '%s'%round_expr(sp.simplify(eq_sp_orig_inputs.diff('cli')), 2)\n",
    "            d[folder]['Equation %d'%eq_num]['$df/dT$'] = '%s'%round_expr(sp.simplify(eq_sp_orig_inputs.diff('ta')), 2)\n",
    "        except: \n",
    "            pass\n",
    "        d[folder]['Equation %d'%eq_num]['Train MSE in regime'] = '%d'%train_mse\n",
    "        d[folder]['Equation %d'%eq_num]['Valid MSE in regime'] = '%d'%valid_mse\n",
    "        if no_of_regimes == 2:\n",
    "            d[folder]['Equation %d'%eq_num]['Train MSE'] = '%d'%mse_all_regimes([train_mse])\n",
    "            d[folder]['Equation %d'%eq_num]['Valid MSE'] = '%d'%mse_all_regimes([valid_mse])\n",
    "\n",
    "        append_dict_to_json(d, os.path.join(folder_abs_path.rsplit('/', maxsplit=2)[0], 'combined_results.json'))\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e258bc-ac8e-45d1-8e92-81d849133e8e",
   "metadata": {},
   "source": [
    "**Process folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa7fc98d-1feb-44e0-a6bc-0e8c6a4ef6df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "abspath = '~/workspace_icon-ml/symbolic_regression/finding_symmetries/pysr_results_dyamond_on_regimes/no_of_regimes_%d'%no_of_regimes\n",
    "\n",
    "ppfolders = os.listdir(abspath)\n",
    "\n",
    "for ppfolder in ppfolders:\n",
    "    # We would have to adjust process_hof_file for the '*_improving_*' output\n",
    "    if ppfolder in ppfolders:\n",
    "        pfolders = os.listdir(os.path.join(abspath, ppfolder))\n",
    "        for folder in pfolders:\n",
    "            if folder.startswith('tmp'):\n",
    "                folder_abs_path=os.path.join(abspath, ppfolder, folder)\n",
    "                process_hof_file(folder_abs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c584627-1130-44de-8d86-b983c2707687",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Validation MSE on the entire dataset\n",
    "\n",
    "Requires all regimes to be present in combined_results.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63724c7b-bbe2-41eb-9567-81d624492a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_of_regimes = 4 # Choose out of [3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "853c04c9-bcdd-4e9d-9a30-2683b2335435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse_reg_0 = 0.0353\n",
    "# n_0 = 32419018\n",
    "\n",
    "# n_21 = 62640812\n",
    "\n",
    "# n_31 = 5742663\n",
    "# n_32 = 56898149\n",
    "\n",
    "# n_41 = 5742663\n",
    "# n_42 = 18367245\n",
    "# n_43 = 38530904\n",
    "\n",
    "# N = n_0 + n_21\n",
    "# print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "664fecf1-6f17-484f-80c1-8dbc161016c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# abspath = '~/workspace_icon-ml/symbolic_regression/finding_symmetries/pysr_results_dyamond_on_regimes/no_of_regimes_%d'%no_of_regimes\n",
    "# combined_results_file = os.path.join(abspath, 'combined_results.json')\n",
    "\n",
    "# reg_folders = {}\n",
    "# reg_folders['regime_1'] = {}\n",
    "# reg_folders['regime_2'] = {}\n",
    "# reg_folders['regime_3'] = {}\n",
    "\n",
    "# print(os.listdir(abspath))\n",
    "# for ppfolder in os.listdir(abspath):\n",
    "#     if ppfolder.startswith('regime'):\n",
    "#         pfolders = os.listdir(os.path.join(abspath, ppfolder))\n",
    "#         reg_folders[ppfolder] = [folder for folder in pfolders if folder.startswith('tmp')]          \n",
    "            \n",
    "# valid_mses_all_data = {}\n",
    "\n",
    "# with open(combined_results_file, 'r') as file:\n",
    "#     d = json.load(file)\n",
    "\n",
    "# #     ## Extract MSEs depending on no_of_regimes\n",
    "# #     if no_of_regimes == 2:\n",
    "# #         # Loop through folders\n",
    "# #         for key_1 in d['regime_1'].keys():\n",
    "# #             # Loop through equation numbers\n",
    "# #             for eq_num_1 in d['regime_1'][key_1].keys():\n",
    "# #                 mse_total = n_0*mse_reg_0\n",
    "# #                 mse_total += float(d['regime_1'][key_1][eq_num_1]['Valid MSE in regime'])*n_21\n",
    "\n",
    "# #                 new_key = (key_1 + '_' + eq_num_1).replace(' ', '_')\n",
    "# #                 valid_mses_all_data[new_key] = mse_total/N\n",
    "    \n",
    "#     if no_of_regimes == 3:\n",
    "#         # Loop through folders\n",
    "#         for key_1 in reg_folders['regime_1']:\n",
    "#             for key_2 in reg_folders['regime_2']:\n",
    "#                 # Loop through equation numbers\n",
    "#                 for eq_num_1 in d[key_1].keys():\n",
    "#                     for eq_num_2 in d[key_2].keys():\n",
    "#                         mse_total = n_0*mse_reg_0\n",
    "#                         mse_total += float(d[key_1][eq_num_1]['Valid MSE in regime'])*n_31    \n",
    "#                         mse_total += float(d[key_2][eq_num_2]['Valid MSE in regime'])*n_32\n",
    "\n",
    "#                         new_key = (key_1 + '_' + eq_num_1 + '_' + key_2 + '_' + eq_num_2).replace(' ', '_')\n",
    "#                         valid_mses_all_data[new_key] = mse_total/N\n",
    "                        \n",
    "#     if no_of_regimes == 4:\n",
    "#         # Loop through folders\n",
    "#         for key_1 in reg_folders['regime_1']:\n",
    "#             for key_2 in reg_folders['regime_2']:\n",
    "#                 for key_3 in reg_folders['regime_3']:\n",
    "#                     # Loop through equation numbers\n",
    "#                     for eq_num_1 in d[key_1].keys():\n",
    "#                         for eq_num_2 in d[key_2].keys():\n",
    "#                             for eq_num_3 in d[key_3].keys():\n",
    "#                                 mse_total = n_0*mse_reg_0\n",
    "#                                 mse_total += float(d[key_1][eq_num_1]['Valid MSE in regime'])*n_41    \n",
    "#                                 mse_total += float(d[key_2][eq_num_2]['Valid MSE in regime'])*n_42\n",
    "#                                 mse_total += float(d[key_3][eq_num_3]['Valid MSE in regime'])*n_43\n",
    "\n",
    "#                                 new_key = (key_1 + '_' + eq_num_1 + '_' + key_2 + '_' + eq_num_2 + '_' + key_3 + '_' + eq_num_3).replace(' ', '_')\n",
    "#                                 valid_mses_all_data[new_key] = mse_total/N\n",
    "\n",
    "# all_valid_mses_file = os.path.join(abspath, 'valid_mses_entire_dataset.json')\n",
    "# with open(all_valid_mses_file, 'w') as file:\n",
    "#     json.dump(valid_mses_all_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a888e402-a173-4d77-88e7-9d9c0701d976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clouds",
   "language": "python",
   "name": "clouds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
